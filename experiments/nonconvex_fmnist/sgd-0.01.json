{"argv": ["train.py", "--seed", "79", "--optimizer", "SGD", "--run_name", "sgd_0.01.json", "--output_path", "experiments/nonconvex_fmnist/sgd-0.01.json", "--dataset", "FMNIST", "--layer_sizes", "784", "100", "10", "--batch_size", "10", "--learning_rate", "0.01", "--weight_decay", "0.001", "--num_epochs", "300", "--download", "--device", "cuda"], "args": {"seed": 79, "optimizer": "SGD", "run_name": "sgd_0.01.json", "output_path": "experiments/nonconvex_fmnist/sgd-0.01.json", "device": "cuda", "dataset": "FMNIST", "dataset_root": "~/datasets/pytorch", "dataset_size": null, "download": true, "layer_sizes": [784, 100, 10], "batch_size": 10, "test_batch_size": 256, "learning_rate": 0.01, "weight_decay": 0.001, "warmup_learning_rate": 0.01, "num_warmup_epochs": 10, "num_outer_epochs": 100, "num_inner_epochs": 5, "inner_epoch_fraction": null, "choose_random_iterate": false, "num_epochs": 300}, "metrics": [{"epoch": 1, "train_loss": 0.6682809463388597, "grad_norm": 0.8063783049583435, "test_error": 0.17196666666666666}, {"epoch": 2, "train_loss": 0.4725954186419646, "grad_norm": 0.663558840751648, "test_error": 0.15281666666666666}, {"epoch": 3, "train_loss": 0.43490913619737454, "grad_norm": 0.4185972809791565, "test_error": 0.14223333333333332}, {"epoch": 4, "train_loss": 0.41081473033409566, "grad_norm": 0.6754201650619507, "test_error": 0.1409}, {"epoch": 5, "train_loss": 0.39476680537996195, "grad_norm": 0.4811084270477295, "test_error": 0.13328333333333334}, {"epoch": 6, "train_loss": 0.380217941719573, "grad_norm": 0.8816397190093994, "test_error": 0.13081666666666666}, {"epoch": 7, "train_loss": 0.37018411031753445, "grad_norm": 0.7923038601875305, "test_error": 0.13096666666666668}, {"epoch": 8, "train_loss": 0.3605295017288687, "grad_norm": 0.4061162769794464, "test_error": 0.12183333333333334}, {"epoch": 9, "train_loss": 0.3534112281362759, "grad_norm": 0.6984095573425293, "test_error": 0.12406666666666667}, {"epoch": 10, "train_loss": 0.3462159310949501, "grad_norm": 0.6126760244369507, "test_error": 0.12011666666666666}, {"epoch": 11, "train_loss": 0.3398435170229059, "grad_norm": 0.4150439500808716, "test_error": 0.11635}, {"epoch": 12, "train_loss": 0.33427532673549526, "grad_norm": 0.7654948830604553, "test_error": 0.12008333333333333}, {"epoch": 13, "train_loss": 0.3299767902464761, "grad_norm": 1.0569547414779663, "test_error": 0.1199}, {"epoch": 14, "train_loss": 0.324997735514907, "grad_norm": 0.4339810013771057, "test_error": 0.11126666666666667}, {"epoch": 15, "train_loss": 0.32132834995320686, "grad_norm": 0.4888920187950134, "test_error": 0.11143333333333333}, {"epoch": 16, "train_loss": 0.31799929349271894, "grad_norm": 0.5391652584075928, "test_error": 0.10788333333333333}, {"epoch": 17, "train_loss": 0.31484286204523715, "grad_norm": 0.45238927006721497, "test_error": 0.10646666666666667}, {"epoch": 18, "train_loss": 0.3116494280048646, "grad_norm": 0.3697114586830139, "test_error": 0.1044}, {"epoch": 19, "train_loss": 0.30807774577949504, "grad_norm": 0.7009868621826172, "test_error": 0.10826666666666666}, {"epoch": 20, "train_loss": 0.30638845682671917, "grad_norm": 0.8158397674560547, "test_error": 0.11008333333333334}, {"epoch": 21, "train_loss": 0.304021515393164, "grad_norm": 0.29388004541397095, "test_error": 0.10098333333333333}, {"epoch": 22, "train_loss": 0.3026124985719022, "grad_norm": 0.3678888976573944, "test_error": 0.10145}, {"epoch": 23, "train_loss": 0.2995989274218834, "grad_norm": 0.34650957584381104, "test_error": 0.102}, {"epoch": 24, "train_loss": 0.2981382506942221, "grad_norm": 0.5699627995491028, "test_error": 0.10273333333333333}, {"epoch": 25, "train_loss": 0.29549855397843444, "grad_norm": 0.4956163763999939, "test_error": 0.10216666666666667}, {"epoch": 26, "train_loss": 0.29435544458179114, "grad_norm": 0.767034113407135, "test_error": 0.10516666666666667}, {"epoch": 27, "train_loss": 0.29224769958062097, "grad_norm": 0.5372245907783508, "test_error": 0.10353333333333334}, {"epoch": 28, "train_loss": 0.2913179967273803, "grad_norm": 0.7021682858467102, "test_error": 0.10426666666666666}, {"epoch": 29, "train_loss": 0.2893901524137861, "grad_norm": 0.32311293482780457, "test_error": 0.096}, {"epoch": 30, "train_loss": 0.28930190073427126, "grad_norm": 0.3986580967903137, "test_error": 0.09715}, {"epoch": 31, "train_loss": 0.287129123577072, "grad_norm": 0.6243111491203308, "test_error": 0.10181666666666667}, {"epoch": 32, "train_loss": 0.285568160448689, "grad_norm": 0.5812053084373474, "test_error": 0.0992}, {"epoch": 33, "train_loss": 0.2850100724410731, "grad_norm": 0.4413459002971649, "test_error": 0.09735}, {"epoch": 34, "train_loss": 0.283223254767945, "grad_norm": 0.34595322608947754, "test_error": 0.09348333333333333}, {"epoch": 35, "train_loss": 0.28311964890221136, "grad_norm": 0.6153554916381836, "test_error": 0.09946666666666666}, {"epoch": 36, "train_loss": 0.28134867500979455, "grad_norm": 0.23918180167675018, "test_error": 0.09148333333333333}, {"epoch": 37, "train_loss": 0.28083231182349844, "grad_norm": 0.8979601263999939, "test_error": 0.10176666666666667}, {"epoch": 38, "train_loss": 0.2793477167196106, "grad_norm": 0.5434297323226929, "test_error": 0.09585}, {"epoch": 39, "train_loss": 0.2785627388202896, "grad_norm": 0.7240170240402222, "test_error": 0.09816666666666667}, {"epoch": 40, "train_loss": 0.2775862439816507, "grad_norm": 0.3482486307621002, "test_error": 0.09245}, {"epoch": 41, "train_loss": 0.2780885593364559, "grad_norm": 0.35131123661994934, "test_error": 0.09233333333333334}, {"epoch": 42, "train_loss": 0.27694091640482654, "grad_norm": 0.34317225217819214, "test_error": 0.09185}, {"epoch": 43, "train_loss": 0.2755971226582769, "grad_norm": 0.5318477749824524, "test_error": 0.0945}, {"epoch": 44, "train_loss": 0.27513702411724567, "grad_norm": 0.5428266525268555, "test_error": 0.09473333333333334}, {"epoch": 45, "train_loss": 0.2743838677985671, "grad_norm": 0.5026238560676575, "test_error": 0.09296666666666667}, {"epoch": 46, "train_loss": 0.2742317860710124, "grad_norm": 0.36373066902160645, "test_error": 0.09068333333333334}, {"epoch": 47, "train_loss": 0.27239113101533924, "grad_norm": 0.7872018814086914, "test_error": 0.10076666666666667}, {"epoch": 48, "train_loss": 0.272628599398459, "grad_norm": 0.3054065704345703, "test_error": 0.09113333333333333}, {"epoch": 49, "train_loss": 0.2720004430707777, "grad_norm": 0.6540143489837646, "test_error": 0.09251666666666666}, {"epoch": 50, "train_loss": 0.27103634601604426, "grad_norm": 0.7522468566894531, "test_error": 0.09753333333333333}, {"epoch": 51, "train_loss": 0.27064128610041616, "grad_norm": 0.294523686170578, "test_error": 0.08856666666666667}, {"epoch": 52, "train_loss": 0.26978057036331543, "grad_norm": 0.31861433386802673, "test_error": 0.08708333333333333}, {"epoch": 53, "train_loss": 0.2689935100075672, "grad_norm": 0.5752663016319275, "test_error": 0.09468333333333333}, {"epoch": 54, "train_loss": 0.2687192044711361, "grad_norm": 0.65604567527771, "test_error": 0.09641666666666666}, {"epoch": 55, "train_loss": 0.26827231582750877, "grad_norm": 0.44810253381729126, "test_error": 0.08935}, {"epoch": 56, "train_loss": 0.2675313063104792, "grad_norm": 0.4747765362262726, "test_error": 0.08863333333333333}, {"epoch": 57, "train_loss": 0.26736717208699945, "grad_norm": 0.36275070905685425, "test_error": 0.08995}, {"epoch": 58, "train_loss": 0.26690794466567846, "grad_norm": 0.3081442713737488, "test_error": 0.08828333333333334}, {"epoch": 59, "train_loss": 0.2670480392272584, "grad_norm": 0.5474225878715515, "test_error": 0.09133333333333334}, {"epoch": 60, "train_loss": 0.26499002977107494, "grad_norm": 0.47545889019966125, "test_error": 0.0882}, {"epoch": 61, "train_loss": 0.2661482594687647, "grad_norm": 0.44996994733810425, "test_error": 0.08786666666666666}, {"epoch": 62, "train_loss": 0.2656446439449986, "grad_norm": 0.31910622119903564, "test_error": 0.08735}, {"epoch": 63, "train_loss": 0.2648559685422418, "grad_norm": 0.34833142161369324, "test_error": 0.08625}, {"epoch": 64, "train_loss": 0.26425132336413176, "grad_norm": 0.5942753553390503, "test_error": 0.08991666666666667}, {"epoch": 65, "train_loss": 0.26536818451523625, "grad_norm": 0.45247113704681396, "test_error": 0.08728333333333334}, {"epoch": 66, "train_loss": 0.26411837807072636, "grad_norm": 0.78255295753479, "test_error": 0.0938}, {"epoch": 67, "train_loss": 0.2628051828085445, "grad_norm": 0.3975958526134491, "test_error": 0.08543333333333333}, {"epoch": 68, "train_loss": 0.26196213615095865, "grad_norm": 0.7033227682113647, "test_error": 0.09376666666666666}, {"epoch": 69, "train_loss": 0.26241322489975333, "grad_norm": 1.1502124071121216, "test_error": 0.10483333333333333}, {"epoch": 70, "train_loss": 0.2624091770076969, "grad_norm": 0.33194661140441895, "test_error": 0.08266666666666667}, {"epoch": 71, "train_loss": 0.2619738675863482, "grad_norm": 0.6828883290290833, "test_error": 0.09273333333333333}, {"epoch": 72, "train_loss": 0.26193553385293733, "grad_norm": 0.6660588979721069, "test_error": 0.09031666666666667}, {"epoch": 73, "train_loss": 0.26052491563294705, "grad_norm": 0.5694082975387573, "test_error": 0.09335}, {"epoch": 74, "train_loss": 0.2620044536118318, "grad_norm": 0.34523579478263855, "test_error": 0.08541666666666667}, {"epoch": 75, "train_loss": 0.26072145222026544, "grad_norm": 0.4245401620864868, "test_error": 0.08751666666666667}, {"epoch": 76, "train_loss": 0.2606579697992808, "grad_norm": 0.8417790532112122, "test_error": 0.09508333333333334}, {"epoch": 77, "train_loss": 0.25909719870068754, "grad_norm": 0.5304269790649414, "test_error": 0.08863333333333333}, {"epoch": 78, "train_loss": 0.2604401606392736, "grad_norm": 0.5763183832168579, "test_error": 0.08863333333333333}, {"epoch": 79, "train_loss": 0.2597239691728416, "grad_norm": 0.40955114364624023, "test_error": 0.08476666666666667}, {"epoch": 80, "train_loss": 0.25939374148477023, "grad_norm": 0.36875301599502563, "test_error": 0.08355}, {"epoch": 81, "train_loss": 0.2595218504475585, "grad_norm": 0.5271947979927063, "test_error": 0.08836666666666666}, {"epoch": 82, "train_loss": 0.25896437308564785, "grad_norm": 0.6219616532325745, "test_error": 0.0915}, {"epoch": 83, "train_loss": 0.25859059633648335, "grad_norm": 0.6119385361671448, "test_error": 0.08686666666666666}, {"epoch": 84, "train_loss": 0.25885507528084173, "grad_norm": 0.4559960961341858, "test_error": 0.08606666666666667}, {"epoch": 85, "train_loss": 0.25852855944998254, "grad_norm": 0.3122886121273041, "test_error": 0.08203333333333333}, {"epoch": 86, "train_loss": 0.2581885000153755, "grad_norm": 0.4943099915981293, "test_error": 0.08801666666666667}, {"epoch": 87, "train_loss": 0.2582648661491306, "grad_norm": 0.24276569485664368, "test_error": 0.08285}, {"epoch": 88, "train_loss": 0.2576480683971895, "grad_norm": 0.47002992033958435, "test_error": 0.08525}, {"epoch": 89, "train_loss": 0.2581405461539204, "grad_norm": 0.39850053191185, "test_error": 0.08806666666666667}, {"epoch": 90, "train_loss": 0.25841406599634015, "grad_norm": 0.6688215136528015, "test_error": 0.09068333333333334}, {"epoch": 91, "train_loss": 0.2574872946059331, "grad_norm": 0.507806122303009, "test_error": 0.08791666666666667}, {"epoch": 92, "train_loss": 0.2579827852860714, "grad_norm": 0.8683391213417053, "test_error": 0.0917}, {"epoch": 93, "train_loss": 0.2574916587138238, "grad_norm": 0.7254572510719299, "test_error": 0.0912}, {"epoch": 94, "train_loss": 0.2568734595386001, "grad_norm": 0.4094284772872925, "test_error": 0.08573333333333333}, {"epoch": 95, "train_loss": 0.2569159249222527, "grad_norm": 0.5508140325546265, "test_error": 0.08678333333333334}, {"epoch": 96, "train_loss": 0.2562581262943568, "grad_norm": 0.621678352355957, "test_error": 0.08853333333333334}, {"epoch": 97, "train_loss": 0.2563524696759026, "grad_norm": 0.5022456645965576, "test_error": 0.08753333333333334}, {"epoch": 98, "train_loss": 0.256383159715139, "grad_norm": 0.44214877486228943, "test_error": 0.08893333333333334}, {"epoch": 99, "train_loss": 0.2564878029030515, "grad_norm": 0.4852517545223236, "test_error": 0.08761666666666666}, {"epoch": 100, "train_loss": 0.2559298408664375, "grad_norm": 0.38849717378616333, "test_error": 0.08355}, {"epoch": 101, "train_loss": 0.2557957743103616, "grad_norm": 0.5807450413703918, "test_error": 0.08733333333333333}, {"epoch": 102, "train_loss": 0.2559840767667629, "grad_norm": 0.4217640459537506, "test_error": 0.08648333333333333}, {"epoch": 103, "train_loss": 0.25649878068702914, "grad_norm": 0.7146673202514648, "test_error": 0.08645}, {"epoch": 104, "train_loss": 0.25541982095874843, "grad_norm": 0.6125146746635437, "test_error": 0.09075}, {"epoch": 105, "train_loss": 0.2555961312085856, "grad_norm": 0.5904445052146912, "test_error": 0.08493333333333333}, {"epoch": 106, "train_loss": 0.25480239777918906, "grad_norm": 0.5684825778007507, "test_error": 0.08486666666666667}, {"epoch": 107, "train_loss": 0.2551248631746663, "grad_norm": 0.6985397934913635, "test_error": 0.08515}, {"epoch": 108, "train_loss": 0.254622652660124, "grad_norm": 0.5933449268341064, "test_error": 0.08548333333333333}, {"epoch": 109, "train_loss": 0.25466442678372064, "grad_norm": 0.40852686762809753, "test_error": 0.08203333333333333}, {"epoch": 110, "train_loss": 0.25348162958965015, "grad_norm": 1.3331934213638306, "test_error": 0.09958333333333333}, {"epoch": 111, "train_loss": 0.25339896049315574, "grad_norm": 0.42417338490486145, "test_error": 0.08335}, {"epoch": 112, "train_loss": 0.25455398768302984, "grad_norm": 0.47974881529808044, "test_error": 0.08318333333333333}, {"epoch": 113, "train_loss": 0.2527959716338664, "grad_norm": 0.7712840437889099, "test_error": 0.09171666666666667}, {"epoch": 114, "train_loss": 0.2531957607533162, "grad_norm": 0.4907779395580292, "test_error": 0.08466666666666667}, {"epoch": 115, "train_loss": 0.25400865253084337, "grad_norm": 0.3628312349319458, "test_error": 0.0839}, {"epoch": 116, "train_loss": 0.25402296167472377, "grad_norm": 0.4121318757534027, "test_error": 0.08248333333333334}, {"epoch": 117, "train_loss": 0.2533812640963588, "grad_norm": 0.8934992551803589, "test_error": 0.09486666666666667}, {"epoch": 118, "train_loss": 0.2538379698874584, "grad_norm": 0.7352077960968018, "test_error": 0.09075}, {"epoch": 119, "train_loss": 0.2529631004013742, "grad_norm": 0.9910003542900085, "test_error": 0.09206666666666667}, {"epoch": 120, "train_loss": 0.2529299811477152, "grad_norm": 0.40828895568847656, "test_error": 0.08236666666666667}, {"epoch": 121, "train_loss": 0.2529175751286869, "grad_norm": 0.9252316951751709, "test_error": 0.0951}, {"epoch": 122, "train_loss": 0.25288027126466234, "grad_norm": 0.5802181959152222, "test_error": 0.08616666666666667}, {"epoch": 123, "train_loss": 0.2530366258932821, "grad_norm": 0.30360350012779236, "test_error": 0.08046666666666667}, {"epoch": 124, "train_loss": 0.25245487624290397, "grad_norm": 0.5852072238922119, "test_error": 0.08625}, {"epoch": 125, "train_loss": 0.25212391737638973, "grad_norm": 0.2621099352836609, "test_error": 0.07981666666666666}, {"epoch": 126, "train_loss": 0.253155520673686, "grad_norm": 0.4120478630065918, "test_error": 0.0825}, {"epoch": 127, "train_loss": 0.2525213928550559, "grad_norm": 0.6513221263885498, "test_error": 0.08661666666666666}, {"epoch": 128, "train_loss": 0.25226763796969315, "grad_norm": 1.2133806943893433, "test_error": 0.10038333333333334}, {"epoch": 129, "train_loss": 0.2527603561439707, "grad_norm": 0.4071943163871765, "test_error": 0.08363333333333334}, {"epoch": 130, "train_loss": 0.2521043956388409, "grad_norm": 0.5849339962005615, "test_error": 0.08638333333333334}, {"epoch": 131, "train_loss": 0.25287970908839874, "grad_norm": 0.3444969952106476, "test_error": 0.07928333333333333}, {"epoch": 132, "train_loss": 0.25154331175334904, "grad_norm": 0.9044067859649658, "test_error": 0.09218333333333334}, {"epoch": 133, "train_loss": 0.25157527833858817, "grad_norm": 0.43458065390586853, "test_error": 0.08358333333333333}, {"epoch": 134, "train_loss": 0.2518749585967356, "grad_norm": 0.55913245677948, "test_error": 0.0834}, {"epoch": 135, "train_loss": 0.25193515974477243, "grad_norm": 0.35926303267478943, "test_error": 0.08251666666666667}, {"epoch": 136, "train_loss": 0.2511126541367654, "grad_norm": 0.5017868876457214, "test_error": 0.08295}, {"epoch": 137, "train_loss": 0.25132939023082146, "grad_norm": 0.2915075421333313, "test_error": 0.08078333333333333}, {"epoch": 138, "train_loss": 0.25140640534681735, "grad_norm": 0.5742311477661133, "test_error": 0.08298333333333334}, {"epoch": 139, "train_loss": 0.2521608934258887, "grad_norm": 0.7404701709747314, "test_error": 0.08601666666666667}, {"epoch": 140, "train_loss": 0.2510825416954079, "grad_norm": 0.820465087890625, "test_error": 0.09055}, {"epoch": 141, "train_loss": 0.250034563149636, "grad_norm": 0.544567346572876, "test_error": 0.08363333333333334}, {"epoch": 142, "train_loss": 0.2509045584342287, "grad_norm": 0.4909704327583313, "test_error": 0.0852}, {"epoch": 143, "train_loss": 0.25124092415735744, "grad_norm": 0.4834510385990143, "test_error": 0.08391666666666667}, {"epoch": 144, "train_loss": 0.2501969475306881, "grad_norm": 0.6259057521820068, "test_error": 0.0831}, {"epoch": 145, "train_loss": 0.2505998928000336, "grad_norm": 0.43546339869499207, "test_error": 0.08036666666666667}, {"epoch": 146, "train_loss": 0.2505202238732018, "grad_norm": 0.4278409481048584, "test_error": 0.08146666666666667}, {"epoch": 147, "train_loss": 0.2508627318192351, "grad_norm": 0.7201943397521973, "test_error": 0.09076666666666666}, {"epoch": 148, "train_loss": 0.25088586405362, "grad_norm": 0.47894951701164246, "test_error": 0.08281666666666666}, {"epoch": 149, "train_loss": 0.24990792917425278, "grad_norm": 0.2929382920265198, "test_error": 0.08135}, {"epoch": 150, "train_loss": 0.24908885092738395, "grad_norm": 0.7174509167671204, "test_error": 0.09151666666666666}, {"epoch": 151, "train_loss": 0.25010169330627346, "grad_norm": 0.25782403349876404, "test_error": 0.07958333333333334}, {"epoch": 152, "train_loss": 0.2502645093018655, "grad_norm": 0.31619563698768616, "test_error": 0.08091666666666666}, {"epoch": 153, "train_loss": 0.2507610468200874, "grad_norm": 0.769943356513977, "test_error": 0.08631666666666667}, {"epoch": 154, "train_loss": 0.25029293408322456, "grad_norm": 0.25522899627685547, "test_error": 0.07995}, {"epoch": 155, "train_loss": 0.25052219871765313, "grad_norm": 0.3305091857910156, "test_error": 0.07865}, {"epoch": 156, "train_loss": 0.24956275429731856, "grad_norm": 0.2650989294052124, "test_error": 0.07911666666666667}, {"epoch": 157, "train_loss": 0.24967464236092443, "grad_norm": 0.7720300555229187, "test_error": 0.08865}, {"epoch": 158, "train_loss": 0.24962893859832547, "grad_norm": 0.2605436146259308, "test_error": 0.07828333333333333}, {"epoch": 159, "train_loss": 0.2504738343064673, "grad_norm": 0.5999457240104675, "test_error": 0.08178333333333333}, {"epoch": 160, "train_loss": 0.25048862539123123, "grad_norm": 0.49442997574806213, "test_error": 0.08431666666666666}, {"epoch": 161, "train_loss": 0.249884999722514, "grad_norm": 0.4774218499660492, "test_error": 0.08271666666666666}, {"epoch": 162, "train_loss": 0.248632411364854, "grad_norm": 0.6029288172721863, "test_error": 0.08503333333333334}, {"epoch": 163, "train_loss": 0.24918178220287276, "grad_norm": 0.27093306183815, "test_error": 0.08081666666666666}, {"epoch": 164, "train_loss": 0.25002708334161433, "grad_norm": 0.2843303382396698, "test_error": 0.07753333333333333}, {"epoch": 165, "train_loss": 0.24974780836643184, "grad_norm": 0.41655808687210083, "test_error": 0.08193333333333333}, {"epoch": 166, "train_loss": 0.24932769004333144, "grad_norm": 0.6173481345176697, "test_error": 0.087}, {"epoch": 167, "train_loss": 0.24978346351611738, "grad_norm": 0.5637650489807129, "test_error": 0.08555}, {"epoch": 168, "train_loss": 0.24914411568884196, "grad_norm": 0.720729649066925, "test_error": 0.08788333333333333}, {"epoch": 169, "train_loss": 0.24972470101426977, "grad_norm": 0.4348679780960083, "test_error": 0.08196666666666666}, {"epoch": 170, "train_loss": 0.2495953694686371, "grad_norm": 0.4343877136707306, "test_error": 0.08323333333333334}, {"epoch": 171, "train_loss": 0.2494659637439375, "grad_norm": 0.39604106545448303, "test_error": 0.08085}, {"epoch": 172, "train_loss": 0.24865198236890138, "grad_norm": 0.41533976793289185, "test_error": 0.0807}, {"epoch": 173, "train_loss": 0.24857781057168418, "grad_norm": 0.5450671911239624, "test_error": 0.08478333333333334}, {"epoch": 174, "train_loss": 0.24902027090856185, "grad_norm": 0.8502180576324463, "test_error": 0.08951666666666666}, {"epoch": 175, "train_loss": 0.2495274821765876, "grad_norm": 0.5593103170394897, "test_error": 0.08418333333333333}, {"epoch": 176, "train_loss": 0.24941726098217382, "grad_norm": 0.2902136743068695, "test_error": 0.07836666666666667}, {"epoch": 177, "train_loss": 0.2485202254112228, "grad_norm": 0.3739568293094635, "test_error": 0.08163333333333334}, {"epoch": 178, "train_loss": 0.24973363665491344, "grad_norm": 0.6231516003608704, "test_error": 0.08503333333333334}, {"epoch": 179, "train_loss": 0.24771872541091094, "grad_norm": 0.48239606618881226, "test_error": 0.08316666666666667}, {"epoch": 180, "train_loss": 0.24917044965573587, "grad_norm": 0.5065494179725647, "test_error": 0.08128333333333333}, {"epoch": 181, "train_loss": 0.24819117939836965, "grad_norm": 0.42538130283355713, "test_error": 0.08178333333333333}, {"epoch": 182, "train_loss": 0.24780588906937434, "grad_norm": 0.24281775951385498, "test_error": 0.07848333333333334}, {"epoch": 183, "train_loss": 0.2486015274838234, "grad_norm": 0.5928274393081665, "test_error": 0.08523333333333333}, {"epoch": 184, "train_loss": 0.24756849223712926, "grad_norm": 0.7616703510284424, "test_error": 0.08455}, {"epoch": 185, "train_loss": 0.24836730710362706, "grad_norm": 0.7047727704048157, "test_error": 0.09088333333333333}, {"epoch": 186, "train_loss": 0.24814233135641553, "grad_norm": 0.5478451251983643, "test_error": 0.08306666666666666}, {"epoch": 187, "train_loss": 0.24769314760167618, "grad_norm": 0.2795807719230652, "test_error": 0.08051666666666667}, {"epoch": 188, "train_loss": 0.2477832077801383, "grad_norm": 0.4381764531135559, "test_error": 0.08151666666666667}, {"epoch": 189, "train_loss": 0.24835243118160483, "grad_norm": 0.6431795358657837, "test_error": 0.0831}, {"epoch": 190, "train_loss": 0.24659637579717672, "grad_norm": 0.20023071765899658, "test_error": 0.0785}, {"epoch": 191, "train_loss": 0.2485077291263733, "grad_norm": 0.6969713568687439, "test_error": 0.08526666666666667}, {"epoch": 192, "train_loss": 0.2476913627787144, "grad_norm": 0.40928423404693604, "test_error": 0.0788}, {"epoch": 193, "train_loss": 0.24806494008012425, "grad_norm": 0.4035716652870178, "test_error": 0.08141666666666666}, {"epoch": 194, "train_loss": 0.24800235319665323, "grad_norm": 0.6480967998504639, "test_error": 0.0832}, {"epoch": 195, "train_loss": 0.2478067116851841, "grad_norm": 0.5256168246269226, "test_error": 0.08123333333333334}, {"epoch": 196, "train_loss": 0.2474381505897812, "grad_norm": 0.33336636424064636, "test_error": 0.07753333333333333}, {"epoch": 197, "train_loss": 0.24693443404363158, "grad_norm": 0.7663301825523376, "test_error": 0.08276666666666667}, {"epoch": 198, "train_loss": 0.24745520550222136, "grad_norm": 0.637484610080719, "test_error": 0.08441666666666667}, {"epoch": 199, "train_loss": 0.2472932697556292, "grad_norm": 0.598097026348114, "test_error": 0.08643333333333333}, {"epoch": 200, "train_loss": 0.2475891588241793, "grad_norm": 0.42596814036369324, "test_error": 0.08161666666666667}, {"epoch": 201, "train_loss": 0.2480698307142981, "grad_norm": 0.5620794296264648, "test_error": 0.08575}, {"epoch": 202, "train_loss": 0.24814842339876728, "grad_norm": 0.34816768765449524, "test_error": 0.07711666666666667}, {"epoch": 203, "train_loss": 0.2469807837723056, "grad_norm": 0.3296740651130676, "test_error": 0.0807}, {"epoch": 204, "train_loss": 0.24743307973766543, "grad_norm": 0.5324311256408691, "test_error": 0.08471666666666666}, {"epoch": 205, "train_loss": 0.2468590704172772, "grad_norm": 0.9369885921478271, "test_error": 0.09225}, {"epoch": 206, "train_loss": 0.24742704860741893, "grad_norm": 0.6025655269622803, "test_error": 0.08193333333333333}, {"epoch": 207, "train_loss": 0.2468660696791485, "grad_norm": 0.30795642733573914, "test_error": 0.0806}, {"epoch": 208, "train_loss": 0.24698264154993618, "grad_norm": 0.24487560987472534, "test_error": 0.07798333333333334}, {"epoch": 209, "train_loss": 0.24674024738821512, "grad_norm": 0.7781384587287903, "test_error": 0.09106666666666667}, {"epoch": 210, "train_loss": 0.2467013753214463, "grad_norm": 0.8509165644645691, "test_error": 0.0898}, {"epoch": 211, "train_loss": 0.24639200753431456, "grad_norm": 0.7164355516433716, "test_error": 0.08663333333333334}, {"epoch": 212, "train_loss": 0.2467981332593287, "grad_norm": 0.7348238229751587, "test_error": 0.08863333333333333}, {"epoch": 213, "train_loss": 0.24641994724283964, "grad_norm": 0.2655513882637024, "test_error": 0.07743333333333334}, {"epoch": 214, "train_loss": 0.2466013994923948, "grad_norm": 0.3261913061141968, "test_error": 0.08053333333333333}, {"epoch": 215, "train_loss": 0.24635142197677246, "grad_norm": 0.4304894208908081, "test_error": 0.07961666666666667}, {"epoch": 216, "train_loss": 0.24699539977323728, "grad_norm": 0.8157517313957214, "test_error": 0.0866}, {"epoch": 217, "train_loss": 0.2463047695714825, "grad_norm": 0.3000967502593994, "test_error": 0.07976666666666667}, {"epoch": 218, "train_loss": 0.24672675641587313, "grad_norm": 0.27941739559173584, "test_error": 0.07941666666666666}, {"epoch": 219, "train_loss": 0.24728896937185588, "grad_norm": 0.3998897671699524, "test_error": 0.07753333333333333}, {"epoch": 220, "train_loss": 0.24665837506662744, "grad_norm": 0.8211451768875122, "test_error": 0.0873}, {"epoch": 221, "train_loss": 0.24640463343557592, "grad_norm": 0.4284070134162903, "test_error": 0.0783}, {"epoch": 222, "train_loss": 0.24648931918758898, "grad_norm": 0.43436092138290405, "test_error": 0.08013333333333333}, {"epoch": 223, "train_loss": 0.2476027404126556, "grad_norm": 0.5873504877090454, "test_error": 0.08495}, {"epoch": 224, "train_loss": 0.24705110544222408, "grad_norm": 1.0215728282928467, "test_error": 0.09175}, {"epoch": 225, "train_loss": 0.2459699616173748, "grad_norm": 0.38445982336997986, "test_error": 0.08376666666666667}, {"epoch": 226, "train_loss": 0.2464188486074563, "grad_norm": 0.2807186543941498, "test_error": 0.07916666666666666}, {"epoch": 227, "train_loss": 0.2459977743177054, "grad_norm": 0.3762242794036865, "test_error": 0.08083333333333333}, {"epoch": 228, "train_loss": 0.24651194540477203, "grad_norm": 0.49839016795158386, "test_error": 0.0824}, {"epoch": 229, "train_loss": 0.24599962688014299, "grad_norm": 0.527474582195282, "test_error": 0.08463333333333334}, {"epoch": 230, "train_loss": 0.24662089896112835, "grad_norm": 0.1988135278224945, "test_error": 0.0776}, {"epoch": 231, "train_loss": 0.24649504921515472, "grad_norm": 0.4042283594608307, "test_error": 0.08131666666666666}, {"epoch": 232, "train_loss": 0.24622803447923314, "grad_norm": 1.0313947200775146, "test_error": 0.08928333333333334}, {"epoch": 233, "train_loss": 0.2467813971519548, "grad_norm": 0.5619207620620728, "test_error": 0.08483333333333333}, {"epoch": 234, "train_loss": 0.24622258001038183, "grad_norm": 0.44552239775657654, "test_error": 0.08008333333333334}, {"epoch": 235, "train_loss": 0.24636402101178342, "grad_norm": 0.5010650753974915, "test_error": 0.0817}, {"epoch": 236, "train_loss": 0.2468228776140604, "grad_norm": 0.8936418294906616, "test_error": 0.09426666666666667}, {"epoch": 237, "train_loss": 0.24613989245751872, "grad_norm": 0.2746988832950592, "test_error": 0.07576666666666666}, {"epoch": 238, "train_loss": 0.24711337950235854, "grad_norm": 0.34504714608192444, "test_error": 0.0813}, {"epoch": 239, "train_loss": 0.24495304853771813, "grad_norm": 0.5930545330047607, "test_error": 0.08268333333333333}, {"epoch": 240, "train_loss": 0.2457463033453872, "grad_norm": 0.6912404298782349, "test_error": 0.08626666666666667}, {"epoch": 241, "train_loss": 0.2457357756231019, "grad_norm": 0.48738864064216614, "test_error": 0.07936666666666667}, {"epoch": 242, "train_loss": 0.24516119119703458, "grad_norm": 0.8043259978294373, "test_error": 0.09221666666666667}, {"epoch": 243, "train_loss": 0.24554302939136202, "grad_norm": 0.23415493965148926, "test_error": 0.07776666666666666}, {"epoch": 244, "train_loss": 0.24555788875433307, "grad_norm": 0.21724675595760345, "test_error": 0.07711666666666667}, {"epoch": 245, "train_loss": 0.24601842871389817, "grad_norm": 0.589378297328949, "test_error": 0.0831}, {"epoch": 246, "train_loss": 0.2455997491789361, "grad_norm": 0.8990035057067871, "test_error": 0.08786666666666666}, {"epoch": 247, "train_loss": 0.24568794693029486, "grad_norm": 0.42585813999176025, "test_error": 0.08038333333333333}, {"epoch": 248, "train_loss": 0.24594589025069338, "grad_norm": 0.42655837535858154, "test_error": 0.07933333333333334}, {"epoch": 249, "train_loss": 0.24626780584279914, "grad_norm": 0.42478832602500916, "test_error": 0.08193333333333333}, {"epoch": 250, "train_loss": 0.24633929984426747, "grad_norm": 0.3796902298927307, "test_error": 0.07951666666666667}, {"epoch": 251, "train_loss": 0.2458333183558037, "grad_norm": 0.7395227551460266, "test_error": 0.08605}, {"epoch": 252, "train_loss": 0.246437357997677, "grad_norm": 0.7024907469749451, "test_error": 0.08608333333333333}, {"epoch": 253, "train_loss": 0.24560129357563953, "grad_norm": 0.3338269591331482, "test_error": 0.07888333333333333}, {"epoch": 254, "train_loss": 0.2467313610963368, "grad_norm": 0.42893409729003906, "test_error": 0.0823}, {"epoch": 255, "train_loss": 0.24579944425673844, "grad_norm": 0.3697826862335205, "test_error": 0.08041666666666666}, {"epoch": 256, "train_loss": 0.24562552627859016, "grad_norm": 0.788149356842041, "test_error": 0.08501666666666667}, {"epoch": 257, "train_loss": 0.24589640807492347, "grad_norm": 0.388706773519516, "test_error": 0.0808}, {"epoch": 258, "train_loss": 0.24517261100486698, "grad_norm": 0.40371018648147583, "test_error": 0.08}, {"epoch": 259, "train_loss": 0.24588682168722154, "grad_norm": 0.3741503953933716, "test_error": 0.08205}, {"epoch": 260, "train_loss": 0.24521903816509683, "grad_norm": 0.48247280716896057, "test_error": 0.08046666666666667}, {"epoch": 261, "train_loss": 0.2456673143277876, "grad_norm": 0.816393256187439, "test_error": 0.0878}, {"epoch": 262, "train_loss": 0.24519440599530934, "grad_norm": 0.6129800081253052, "test_error": 0.08348333333333334}, {"epoch": 263, "train_loss": 0.24545527025292782, "grad_norm": 0.2262914925813675, "test_error": 0.07778333333333333}, {"epoch": 264, "train_loss": 0.24535451510595158, "grad_norm": 0.28771212697029114, "test_error": 0.08043333333333333}, {"epoch": 265, "train_loss": 0.24514391957200132, "grad_norm": 0.792251467704773, "test_error": 0.08875}, {"epoch": 266, "train_loss": 0.2450466077485277, "grad_norm": 0.33751651644706726, "test_error": 0.07871666666666667}, {"epoch": 267, "train_loss": 0.24584653778909707, "grad_norm": 0.5652691721916199, "test_error": 0.08226666666666667}, {"epoch": 268, "train_loss": 0.24498990591677527, "grad_norm": 0.5647818446159363, "test_error": 0.0819}, {"epoch": 269, "train_loss": 0.2453341306988926, "grad_norm": 0.46205535531044006, "test_error": 0.08296666666666666}, {"epoch": 270, "train_loss": 0.24472407101327553, "grad_norm": 0.973797082901001, "test_error": 0.0904}, {"epoch": 271, "train_loss": 0.24546415510339042, "grad_norm": 0.44760218262672424, "test_error": 0.08063333333333333}, {"epoch": 272, "train_loss": 0.245361087604193, "grad_norm": 0.3714151084423065, "test_error": 0.08141666666666666}, {"epoch": 273, "train_loss": 0.24545555429222682, "grad_norm": 0.5478112101554871, "test_error": 0.08406666666666666}, {"epoch": 274, "train_loss": 0.24554523963966252, "grad_norm": 0.5892168283462524, "test_error": 0.08286666666666667}, {"epoch": 275, "train_loss": 0.24517001503220914, "grad_norm": 0.5495256781578064, "test_error": 0.08191666666666667}, {"epoch": 276, "train_loss": 0.24632577887495669, "grad_norm": 0.26957476139068604, "test_error": 0.07575}, {"epoch": 277, "train_loss": 0.24500352384522558, "grad_norm": 0.509082019329071, "test_error": 0.07991666666666666}, {"epoch": 278, "train_loss": 0.2456338279637275, "grad_norm": 0.6423172950744629, "test_error": 0.0822}, {"epoch": 279, "train_loss": 0.24383014695672317, "grad_norm": 0.46023085713386536, "test_error": 0.08106666666666666}, {"epoch": 280, "train_loss": 0.2450441795504885, "grad_norm": 0.3492579758167267, "test_error": 0.07871666666666667}, {"epoch": 281, "train_loss": 0.2456328343305892, "grad_norm": 0.4886339008808136, "test_error": 0.08141666666666666}, {"epoch": 282, "train_loss": 0.24448965419308905, "grad_norm": 0.856178343296051, "test_error": 0.08935}, {"epoch": 283, "train_loss": 0.24379514692234808, "grad_norm": 0.6044915914535522, "test_error": 0.08581666666666667}, {"epoch": 284, "train_loss": 0.24509684899798595, "grad_norm": 0.3916099965572357, "test_error": 0.08018333333333333}, {"epoch": 285, "train_loss": 0.24495127179236928, "grad_norm": 0.780876636505127, "test_error": 0.08671666666666666}, {"epoch": 286, "train_loss": 0.24583029143275537, "grad_norm": 0.4510357677936554, "test_error": 0.08181666666666666}, {"epoch": 287, "train_loss": 0.24545472696927997, "grad_norm": 0.30980560183525085, "test_error": 0.07783333333333334}, {"epoch": 288, "train_loss": 0.24480127566408677, "grad_norm": 0.3482837975025177, "test_error": 0.08125}, {"epoch": 289, "train_loss": 0.2454864797492822, "grad_norm": 0.7909747958183289, "test_error": 0.08576666666666667}, {"epoch": 290, "train_loss": 0.24528181368717925, "grad_norm": 0.60527104139328, "test_error": 0.08588333333333334}, {"epoch": 291, "train_loss": 0.24465790045447647, "grad_norm": 0.5514130592346191, "test_error": 0.0856}, {"epoch": 292, "train_loss": 0.24538303170617048, "grad_norm": 0.5636003017425537, "test_error": 0.07981666666666666}, {"epoch": 293, "train_loss": 0.24545854710869025, "grad_norm": 0.4824482500553131, "test_error": 0.08065}, {"epoch": 294, "train_loss": 0.24432005106366705, "grad_norm": 0.4219803214073181, "test_error": 0.079}, {"epoch": 295, "train_loss": 0.24480521693763632, "grad_norm": 0.8193849921226501, "test_error": 0.08651666666666667}, {"epoch": 296, "train_loss": 0.24462958974853002, "grad_norm": 0.42185652256011963, "test_error": 0.08323333333333334}, {"epoch": 297, "train_loss": 0.24477014144564357, "grad_norm": 0.2679680585861206, "test_error": 0.0766}, {"epoch": 298, "train_loss": 0.24412453694152647, "grad_norm": 0.48034214973449707, "test_error": 0.08105}, {"epoch": 299, "train_loss": 0.24452386415396662, "grad_norm": 0.3924521207809448, "test_error": 0.08125}, {"epoch": 300, "train_loss": 0.24481743722498261, "grad_norm": 1.045401692390442, "test_error": 0.09058333333333334}]}