{"argv": ["train.py", "--seed", "79", "--optimizer", "SGD", "--run_name", "sgd_0.5.json", "--output_path", "experiments/nonconvex_fmnist/sgd-0.5.json", "--dataset", "FMNIST", "--layer_sizes", "784", "100", "10", "--batch_size", "10", "--learning_rate", "0.5", "--weight_decay", "0.001", "--num_epochs", "300", "--download", "--device", "cuda"], "args": {"seed": 79, "optimizer": "SGD", "run_name": "sgd_0.5.json", "output_path": "experiments/nonconvex_fmnist/sgd-0.5.json", "device": "cuda", "dataset": "FMNIST", "dataset_root": "~/datasets/pytorch", "dataset_size": null, "download": true, "layer_sizes": [784, 100, 10], "batch_size": 10, "test_batch_size": 256, "learning_rate": 0.5, "weight_decay": 0.001, "warmup_learning_rate": 0.01, "num_warmup_epochs": 10, "num_outer_epochs": 100, "num_inner_epochs": 5, "inner_epoch_fraction": null, "choose_random_iterate": false, "num_epochs": 300}, "metrics": [{"epoch": 1, "train_loss": 2.0915247169236344, "grad_norm": 0.7283598184585571, "test_error": 0.7963833333333333}, {"epoch": 2, "train_loss": 2.2570822949608167, "grad_norm": 0.04057120159268379, "test_error": 0.9}, {"epoch": 3, "train_loss": 2.3090993685324985, "grad_norm": 0.03532412275671959, "test_error": 0.9}, {"epoch": 4, "train_loss": 2.3140626393556594, "grad_norm": 0.05395858362317085, "test_error": 0.9}, {"epoch": 5, "train_loss": 2.3140882816314696, "grad_norm": 0.05786224454641342, "test_error": 0.9}, {"epoch": 6, "train_loss": 2.3105838050643603, "grad_norm": 0.042268961668014526, "test_error": 0.9}, {"epoch": 7, "train_loss": 2.31400380953153, "grad_norm": 0.0695570781826973, "test_error": 0.9}, {"epoch": 8, "train_loss": 2.313902719815572, "grad_norm": 0.03743954375386238, "test_error": 0.9}, {"epoch": 9, "train_loss": 2.314356059551239, "grad_norm": 0.042654357850551605, "test_error": 0.9}, {"epoch": 10, "train_loss": 2.313910591721535, "grad_norm": 0.04837937653064728, "test_error": 0.9}, {"epoch": 11, "train_loss": 2.3138292448918025, "grad_norm": 0.04665283486247063, "test_error": 0.9}, {"epoch": 12, "train_loss": 2.314811594804128, "grad_norm": 0.03208765760064125, "test_error": 0.9}, {"epoch": 13, "train_loss": 2.3140663818915685, "grad_norm": 0.03419815003871918, "test_error": 0.9}, {"epoch": 14, "train_loss": 2.3141370575030646, "grad_norm": 0.05374789237976074, "test_error": 0.9}, {"epoch": 15, "train_loss": 2.3138412433067956, "grad_norm": 0.04585374519228935, "test_error": 0.9}, {"epoch": 16, "train_loss": 2.3147824982007346, "grad_norm": 0.06144316494464874, "test_error": 0.9}, {"epoch": 17, "train_loss": 2.3144380184809368, "grad_norm": 0.05307622626423836, "test_error": 0.9}, {"epoch": 18, "train_loss": 2.314484403729439, "grad_norm": 0.04300767183303833, "test_error": 0.9}, {"epoch": 19, "train_loss": 2.3133391537268957, "grad_norm": 0.046947821974754333, "test_error": 0.9}, {"epoch": 20, "train_loss": 2.3143301862080894, "grad_norm": 0.05621449276804924, "test_error": 0.9}, {"epoch": 21, "train_loss": 2.314371422012647, "grad_norm": 0.049268774688243866, "test_error": 0.9}, {"epoch": 22, "train_loss": 2.3137962800661724, "grad_norm": 0.04182520881295204, "test_error": 0.9}, {"epoch": 23, "train_loss": 2.3145914981762568, "grad_norm": 0.04193124175071716, "test_error": 0.9}, {"epoch": 24, "train_loss": 2.3137825464804966, "grad_norm": 0.06396409869194031, "test_error": 0.9}, {"epoch": 25, "train_loss": 2.3140459162394205, "grad_norm": 0.037476662546396255, "test_error": 0.9}, {"epoch": 26, "train_loss": 2.313779015262922, "grad_norm": 0.04523080587387085, "test_error": 0.9}, {"epoch": 27, "train_loss": 2.3140534840424856, "grad_norm": 0.052838318049907684, "test_error": 0.9}, {"epoch": 28, "train_loss": 2.3138790509303413, "grad_norm": 0.07173441350460052, "test_error": 0.9}, {"epoch": 29, "train_loss": 2.3140807968378065, "grad_norm": 0.057112205773591995, "test_error": 0.9}, {"epoch": 30, "train_loss": 2.313922555645307, "grad_norm": 0.025265689939260483, "test_error": 0.9}, {"epoch": 31, "train_loss": 2.314136716902256, "grad_norm": 0.05470636859536171, "test_error": 0.9}, {"epoch": 32, "train_loss": 2.3080729826887447, "grad_norm": 0.04974794015288353, "test_error": 0.9}, {"epoch": 33, "train_loss": 2.3141730106274285, "grad_norm": 0.05574764683842659, "test_error": 0.9}, {"epoch": 34, "train_loss": 2.313284289697806, "grad_norm": 0.02509048581123352, "test_error": 0.9}, {"epoch": 35, "train_loss": 2.31344426937898, "grad_norm": 0.060506246984004974, "test_error": 0.9}, {"epoch": 36, "train_loss": 2.313661338965098, "grad_norm": 0.03386109322309494, "test_error": 0.9}, {"epoch": 37, "train_loss": 2.3141620011727015, "grad_norm": 0.05330910161137581, "test_error": 0.9}, {"epoch": 38, "train_loss": 2.313556338787079, "grad_norm": 0.035704851150512695, "test_error": 0.9}, {"epoch": 39, "train_loss": 2.313776758670807, "grad_norm": 0.03826332092285156, "test_error": 0.9}, {"epoch": 40, "train_loss": 2.313840551575025, "grad_norm": 0.045546967536211014, "test_error": 0.9}, {"epoch": 41, "train_loss": 2.314359250307083, "grad_norm": 0.038712698966264725, "test_error": 0.9}, {"epoch": 42, "train_loss": 2.3135191617806754, "grad_norm": 0.03675302863121033, "test_error": 0.9}, {"epoch": 43, "train_loss": 2.314314808567365, "grad_norm": 0.05376932770013809, "test_error": 0.9}, {"epoch": 44, "train_loss": 2.314222919265429, "grad_norm": 0.04236150160431862, "test_error": 0.9}, {"epoch": 45, "train_loss": 2.3123663248419764, "grad_norm": 0.03565727546811104, "test_error": 0.9}, {"epoch": 46, "train_loss": 2.3142976915041604, "grad_norm": 0.037692226469516754, "test_error": 0.9}, {"epoch": 47, "train_loss": 2.3138829283714295, "grad_norm": 0.05107799544930458, "test_error": 0.9}, {"epoch": 48, "train_loss": 2.3138734031915664, "grad_norm": 0.037538062781095505, "test_error": 0.9}, {"epoch": 49, "train_loss": 2.3135041537682217, "grad_norm": 0.04667266830801964, "test_error": 0.9}, {"epoch": 50, "train_loss": 2.313918253103892, "grad_norm": 0.0497623011469841, "test_error": 0.9}, {"epoch": 51, "train_loss": 2.3140555746157965, "grad_norm": 0.038747355341911316, "test_error": 0.9}, {"epoch": 52, "train_loss": 2.3140201433499654, "grad_norm": 0.05372457951307297, "test_error": 0.9}, {"epoch": 53, "train_loss": 2.3144741187493008, "grad_norm": 0.03374679759144783, "test_error": 0.9}, {"epoch": 54, "train_loss": 2.3139560519854228, "grad_norm": 0.05610816553235054, "test_error": 0.9}, {"epoch": 55, "train_loss": 2.3142579448223115, "grad_norm": 0.04130608215928078, "test_error": 0.9}, {"epoch": 56, "train_loss": 2.3142171407540637, "grad_norm": 0.046157106757164, "test_error": 0.9}, {"epoch": 57, "train_loss": 2.3147379823128382, "grad_norm": 0.031640373170375824, "test_error": 0.9}, {"epoch": 58, "train_loss": 2.314581374804179, "grad_norm": 0.05299854278564453, "test_error": 0.9}, {"epoch": 59, "train_loss": 2.3137441359361013, "grad_norm": 0.040734436362981796, "test_error": 0.9}, {"epoch": 60, "train_loss": 2.31379358569781, "grad_norm": 0.05356277525424957, "test_error": 0.9}, {"epoch": 61, "train_loss": 2.3141293577750526, "grad_norm": 0.03561221808195114, "test_error": 0.9}, {"epoch": 62, "train_loss": 2.314374650756518, "grad_norm": 0.03163713589310646, "test_error": 0.9}, {"epoch": 63, "train_loss": 2.3143426276048022, "grad_norm": 0.03901918977499008, "test_error": 0.9}, {"epoch": 64, "train_loss": 2.3143123532136283, "grad_norm": 0.03217476233839989, "test_error": 0.9}, {"epoch": 65, "train_loss": 2.3140342456499736, "grad_norm": 0.03126782178878784, "test_error": 0.9}, {"epoch": 66, "train_loss": 2.314320763746897, "grad_norm": 0.04218100383877754, "test_error": 0.9}, {"epoch": 67, "train_loss": 2.3139087442954382, "grad_norm": 0.05753243342041969, "test_error": 0.9}, {"epoch": 68, "train_loss": 2.313939762790998, "grad_norm": 0.0448111817240715, "test_error": 0.9}, {"epoch": 69, "train_loss": 2.313866139729818, "grad_norm": 0.0366324745118618, "test_error": 0.9}, {"epoch": 70, "train_loss": 2.31431459736824, "grad_norm": 0.027343034744262695, "test_error": 0.9}, {"epoch": 71, "train_loss": 2.3143410798311232, "grad_norm": 0.06178058683872223, "test_error": 0.9}, {"epoch": 72, "train_loss": 2.314464960694313, "grad_norm": 0.05709933117032051, "test_error": 0.9}, {"epoch": 73, "train_loss": 2.3141899555524192, "grad_norm": 0.05467785894870758, "test_error": 0.9}, {"epoch": 74, "train_loss": 2.3140356202522914, "grad_norm": 0.031143389642238617, "test_error": 0.9}, {"epoch": 75, "train_loss": 2.3137808428605395, "grad_norm": 0.036313414573669434, "test_error": 0.9}, {"epoch": 76, "train_loss": 2.3143876177867253, "grad_norm": 0.05442642793059349, "test_error": 0.9}, {"epoch": 77, "train_loss": 2.3138554991086324, "grad_norm": 0.06426247954368591, "test_error": 0.9}, {"epoch": 78, "train_loss": 2.3139030858278273, "grad_norm": 0.035302452743053436, "test_error": 0.9}, {"epoch": 79, "train_loss": 2.3142965352535247, "grad_norm": 0.05314231663942337, "test_error": 0.9}, {"epoch": 80, "train_loss": 2.3134617795944212, "grad_norm": 0.051552195101976395, "test_error": 0.9}, {"epoch": 81, "train_loss": 2.3146672755082447, "grad_norm": 0.05664124712347984, "test_error": 0.9}, {"epoch": 82, "train_loss": 2.3138905751705168, "grad_norm": 0.048835646361112595, "test_error": 0.9}, {"epoch": 83, "train_loss": 2.314516320943832, "grad_norm": 0.04400525614619255, "test_error": 0.9}, {"epoch": 84, "train_loss": 2.3141970688899356, "grad_norm": 0.04434983432292938, "test_error": 0.9}, {"epoch": 85, "train_loss": 2.3140038031339647, "grad_norm": 0.052131351083517075, "test_error": 0.9}, {"epoch": 86, "train_loss": 2.3136122930447263, "grad_norm": 0.05244690179824829, "test_error": 0.9}, {"epoch": 87, "train_loss": 2.3143610729376474, "grad_norm": 0.03319660946726799, "test_error": 0.9}, {"epoch": 88, "train_loss": 2.3135621055761972, "grad_norm": 0.03152185305953026, "test_error": 0.9}, {"epoch": 89, "train_loss": 2.3141878157059352, "grad_norm": 0.03452928364276886, "test_error": 0.9}, {"epoch": 90, "train_loss": 2.314524915218353, "grad_norm": 0.030420836061239243, "test_error": 0.9}, {"epoch": 91, "train_loss": 2.313978566090266, "grad_norm": 0.04661848396062851, "test_error": 0.9}, {"epoch": 92, "train_loss": 2.3145662767887116, "grad_norm": 0.027853606268763542, "test_error": 0.9}, {"epoch": 93, "train_loss": 2.3139823670784634, "grad_norm": 0.06659609079360962, "test_error": 0.9}, {"epoch": 94, "train_loss": 2.314618579387665, "grad_norm": 0.04439600184559822, "test_error": 0.9}, {"epoch": 95, "train_loss": 2.3137177363236745, "grad_norm": 0.03486817330121994, "test_error": 0.9}, {"epoch": 96, "train_loss": 2.314196378032366, "grad_norm": 0.033579159528017044, "test_error": 0.9}, {"epoch": 97, "train_loss": 2.314275284409523, "grad_norm": 0.057625312358140945, "test_error": 0.9}, {"epoch": 98, "train_loss": 2.313766937216123, "grad_norm": 0.050712671130895615, "test_error": 0.9}, {"epoch": 99, "train_loss": 2.314277796069781, "grad_norm": 0.047443848103284836, "test_error": 0.9}, {"epoch": 100, "train_loss": 2.314083944241206, "grad_norm": 0.03234657272696495, "test_error": 0.9}, {"epoch": 101, "train_loss": 2.313752122203509, "grad_norm": 0.048505593091249466, "test_error": 0.9}, {"epoch": 102, "train_loss": 2.314779533147812, "grad_norm": 0.050877224653959274, "test_error": 0.9}, {"epoch": 103, "train_loss": 2.3135677840312323, "grad_norm": 0.05709606781601906, "test_error": 0.9}, {"epoch": 104, "train_loss": 2.313889165878296, "grad_norm": 0.058606382459402084, "test_error": 0.9}, {"epoch": 105, "train_loss": 2.313679477294286, "grad_norm": 0.037696920335292816, "test_error": 0.9}, {"epoch": 106, "train_loss": 2.3145227417945864, "grad_norm": 0.053507719188928604, "test_error": 0.9}, {"epoch": 107, "train_loss": 2.3137614717086157, "grad_norm": 0.03667458891868591, "test_error": 0.9}, {"epoch": 108, "train_loss": 2.313786659240723, "grad_norm": 0.0420607253909111, "test_error": 0.9}, {"epoch": 109, "train_loss": 2.314104609688123, "grad_norm": 0.0338134728372097, "test_error": 0.9}, {"epoch": 110, "train_loss": 2.3138126494487126, "grad_norm": 0.042699310928583145, "test_error": 0.9}, {"epoch": 111, "train_loss": 2.313647152543068, "grad_norm": 0.04640696570277214, "test_error": 0.9}, {"epoch": 112, "train_loss": 2.3147362216711045, "grad_norm": 0.03018062375485897, "test_error": 0.9}, {"epoch": 113, "train_loss": 2.3142391578356425, "grad_norm": 0.05876288190484047, "test_error": 0.9}, {"epoch": 114, "train_loss": 2.313500202258428, "grad_norm": 0.07059294730424881, "test_error": 0.9}, {"epoch": 115, "train_loss": 2.3137752298116685, "grad_norm": 0.06583258509635925, "test_error": 0.9}, {"epoch": 116, "train_loss": 2.3140404394865035, "grad_norm": 0.06033773347735405, "test_error": 0.9}, {"epoch": 117, "train_loss": 2.3134559976259865, "grad_norm": 0.05396934598684311, "test_error": 0.9}, {"epoch": 118, "train_loss": 2.314639599164327, "grad_norm": 0.04475640505552292, "test_error": 0.9}, {"epoch": 119, "train_loss": 2.3141038800080618, "grad_norm": 0.04238135740160942, "test_error": 0.9}, {"epoch": 120, "train_loss": 2.313722315986951, "grad_norm": 0.03523664548993111, "test_error": 0.9}, {"epoch": 121, "train_loss": 2.3141043207248053, "grad_norm": 0.05524556711316109, "test_error": 0.9}, {"epoch": 122, "train_loss": 2.314165712912877, "grad_norm": 0.04619511589407921, "test_error": 0.9}, {"epoch": 123, "train_loss": 2.3138885597785315, "grad_norm": 0.05810077488422394, "test_error": 0.9}, {"epoch": 124, "train_loss": 2.3141425749460858, "grad_norm": 0.06007970869541168, "test_error": 0.9}, {"epoch": 125, "train_loss": 2.313769322236379, "grad_norm": 0.05513083562254906, "test_error": 0.9}, {"epoch": 126, "train_loss": 2.3137671549717584, "grad_norm": 0.0603131465613842, "test_error": 0.9}, {"epoch": 127, "train_loss": 2.3147306133906045, "grad_norm": 0.04693054035305977, "test_error": 0.9}, {"epoch": 128, "train_loss": 2.3142905632654824, "grad_norm": 0.0708804801106453, "test_error": 0.9}, {"epoch": 129, "train_loss": 2.314133882641792, "grad_norm": 0.04886254668235779, "test_error": 0.9}, {"epoch": 130, "train_loss": 2.31378489891688, "grad_norm": 0.04204820469021797, "test_error": 0.9}, {"epoch": 131, "train_loss": 2.314633803208669, "grad_norm": 0.06484400480985641, "test_error": 0.9}, {"epoch": 132, "train_loss": 2.3137710045576094, "grad_norm": 0.025422563776373863, "test_error": 0.9}, {"epoch": 133, "train_loss": 2.3142361471652984, "grad_norm": 0.0260116308927536, "test_error": 0.9}, {"epoch": 134, "train_loss": 2.3145825624863305, "grad_norm": 0.042682092636823654, "test_error": 0.9}, {"epoch": 135, "train_loss": 2.3139915036757785, "grad_norm": 0.05609629303216934, "test_error": 0.9}, {"epoch": 136, "train_loss": 2.3141657589673996, "grad_norm": 0.06755627691745758, "test_error": 0.9}, {"epoch": 137, "train_loss": 2.3146509757041933, "grad_norm": 0.019795987755060196, "test_error": 0.9}, {"epoch": 138, "train_loss": 2.3140777239402137, "grad_norm": 0.03569074347615242, "test_error": 0.9}, {"epoch": 139, "train_loss": 2.313894333521525, "grad_norm": 0.04110178351402283, "test_error": 0.9}, {"epoch": 140, "train_loss": 2.3139416176080703, "grad_norm": 0.05558668449521065, "test_error": 0.9}, {"epoch": 141, "train_loss": 2.3143801267147066, "grad_norm": 0.038120657205581665, "test_error": 0.9}, {"epoch": 142, "train_loss": 2.3144987402757007, "grad_norm": 0.050926294177770615, "test_error": 0.9}, {"epoch": 143, "train_loss": 2.314099979519844, "grad_norm": 0.05487195774912834, "test_error": 0.9}, {"epoch": 144, "train_loss": 2.313645566264788, "grad_norm": 0.0664111077785492, "test_error": 0.9}, {"epoch": 145, "train_loss": 2.314335770050685, "grad_norm": 0.052335552871227264, "test_error": 0.9}, {"epoch": 146, "train_loss": 2.3140108649333317, "grad_norm": 0.0581052228808403, "test_error": 0.9}, {"epoch": 147, "train_loss": 2.314338610649109, "grad_norm": 0.0537923201918602, "test_error": 0.9}, {"epoch": 148, "train_loss": 2.3145376407702765, "grad_norm": 0.037259217351675034, "test_error": 0.9}, {"epoch": 149, "train_loss": 2.313828219731649, "grad_norm": 0.04724333435297012, "test_error": 0.9}, {"epoch": 150, "train_loss": 2.314322612086932, "grad_norm": 0.03981902077794075, "test_error": 0.9}, {"epoch": 151, "train_loss": 2.3142601035833357, "grad_norm": 0.025040995329618454, "test_error": 0.9}, {"epoch": 152, "train_loss": 2.3141661700407665, "grad_norm": 0.05202016606926918, "test_error": 0.9}, {"epoch": 153, "train_loss": 2.313472984313965, "grad_norm": 0.04580313339829445, "test_error": 0.9}, {"epoch": 154, "train_loss": 2.3142384030024212, "grad_norm": 0.07046366482973099, "test_error": 0.9}, {"epoch": 155, "train_loss": 2.3140877808729807, "grad_norm": 0.060577962547540665, "test_error": 0.9}, {"epoch": 156, "train_loss": 2.31426176349322, "grad_norm": 0.03476249426603317, "test_error": 0.9}, {"epoch": 157, "train_loss": 2.3142958435217538, "grad_norm": 0.05386687442660332, "test_error": 0.9}, {"epoch": 158, "train_loss": 2.3138415728012722, "grad_norm": 0.030878961086273193, "test_error": 0.9}, {"epoch": 159, "train_loss": 2.3140628565947217, "grad_norm": 0.04461740329861641, "test_error": 0.9}, {"epoch": 160, "train_loss": 2.3145839046239853, "grad_norm": 0.032014887779951096, "test_error": 0.9}, {"epoch": 161, "train_loss": 2.313671508272489, "grad_norm": 0.01872042752802372, "test_error": 0.9}, {"epoch": 162, "train_loss": 2.3139082094430923, "grad_norm": 0.049046292901039124, "test_error": 0.9}, {"epoch": 163, "train_loss": 2.314030416170756, "grad_norm": 0.03253714367747307, "test_error": 0.9}, {"epoch": 164, "train_loss": 2.313853713274002, "grad_norm": 0.05256279185414314, "test_error": 0.9}, {"epoch": 165, "train_loss": 2.3136258525848388, "grad_norm": 0.06603006273508072, "test_error": 0.9}, {"epoch": 166, "train_loss": 2.3141402415037153, "grad_norm": 0.038644708693027496, "test_error": 0.9}, {"epoch": 167, "train_loss": 2.3139964954853056, "grad_norm": 0.05469609051942825, "test_error": 0.9}, {"epoch": 168, "train_loss": 2.3145881470839185, "grad_norm": 0.03791488707065582, "test_error": 0.9}, {"epoch": 169, "train_loss": 2.3138216813405355, "grad_norm": 0.03621745482087135, "test_error": 0.9}, {"epoch": 170, "train_loss": 2.314078590075175, "grad_norm": 0.030633078888058662, "test_error": 0.9}, {"epoch": 171, "train_loss": 2.314059131026268, "grad_norm": 0.04297611489892006, "test_error": 0.9}, {"epoch": 172, "train_loss": 2.3134487538735073, "grad_norm": 0.04151919484138489, "test_error": 0.9}, {"epoch": 173, "train_loss": 2.314096439242363, "grad_norm": 0.03352492302656174, "test_error": 0.9}, {"epoch": 174, "train_loss": 2.314114686449369, "grad_norm": 0.0299014113843441, "test_error": 0.9}, {"epoch": 175, "train_loss": 2.3144420983393985, "grad_norm": 0.06068464368581772, "test_error": 0.9}, {"epoch": 176, "train_loss": 2.3137684521277744, "grad_norm": 0.029304809868335724, "test_error": 0.9}, {"epoch": 177, "train_loss": 2.313809412439664, "grad_norm": 0.05984649434685707, "test_error": 0.9}, {"epoch": 178, "train_loss": 2.314627878944079, "grad_norm": 0.05045822262763977, "test_error": 0.9}, {"epoch": 179, "train_loss": 2.3140398495197294, "grad_norm": 0.05581625923514366, "test_error": 0.9}, {"epoch": 180, "train_loss": 2.3137576349576316, "grad_norm": 0.042881645262241364, "test_error": 0.9}, {"epoch": 181, "train_loss": 2.313418685555458, "grad_norm": 0.03995756804943085, "test_error": 0.9}, {"epoch": 182, "train_loss": 2.3143349651495617, "grad_norm": 0.03183305636048317, "test_error": 0.9}, {"epoch": 183, "train_loss": 2.3143353586594264, "grad_norm": 0.05153197795152664, "test_error": 0.9}, {"epoch": 184, "train_loss": 2.3146028414169946, "grad_norm": 0.05988072603940964, "test_error": 0.9}, {"epoch": 185, "train_loss": 2.3139505877892175, "grad_norm": 0.04386349394917488, "test_error": 0.9}, {"epoch": 186, "train_loss": 2.31415347580115, "grad_norm": 0.048871468752622604, "test_error": 0.9}, {"epoch": 187, "train_loss": 2.3144595083793003, "grad_norm": 0.03383822739124298, "test_error": 0.9}, {"epoch": 188, "train_loss": 2.3135161988337836, "grad_norm": 0.0365862138569355, "test_error": 0.9}, {"epoch": 189, "train_loss": 2.313429431994756, "grad_norm": 0.026831256225705147, "test_error": 0.9}, {"epoch": 190, "train_loss": 2.3141193221012752, "grad_norm": 0.036840733140707016, "test_error": 0.9}, {"epoch": 191, "train_loss": 2.3133655153512955, "grad_norm": 0.03327837586402893, "test_error": 0.9}, {"epoch": 192, "train_loss": 2.314149196902911, "grad_norm": 0.04058238863945007, "test_error": 0.9}, {"epoch": 193, "train_loss": 2.3138248086770377, "grad_norm": 0.03581934794783592, "test_error": 0.9}, {"epoch": 194, "train_loss": 2.313833892504374, "grad_norm": 0.032269593328237534, "test_error": 0.9}, {"epoch": 195, "train_loss": 2.3145176560084026, "grad_norm": 0.027196606621146202, "test_error": 0.9}, {"epoch": 196, "train_loss": 2.314120396574338, "grad_norm": 0.03527003899216652, "test_error": 0.9}, {"epoch": 197, "train_loss": 2.3135059099992117, "grad_norm": 0.06576646119356155, "test_error": 0.9}, {"epoch": 198, "train_loss": 2.314032804489136, "grad_norm": 0.049383483827114105, "test_error": 0.9}, {"epoch": 199, "train_loss": 2.314375157793363, "grad_norm": 0.05078643932938576, "test_error": 0.9}, {"epoch": 200, "train_loss": 2.3142320672273637, "grad_norm": 0.06325528770685196, "test_error": 0.9}, {"epoch": 201, "train_loss": 2.3141824998458227, "grad_norm": 0.038295429199934006, "test_error": 0.9}, {"epoch": 202, "train_loss": 2.3142495805819827, "grad_norm": 0.046304453164339066, "test_error": 0.9}, {"epoch": 203, "train_loss": 2.313733701984088, "grad_norm": 0.030069364234805107, "test_error": 0.9}, {"epoch": 204, "train_loss": 2.3136608416636784, "grad_norm": 0.04451169818639755, "test_error": 0.9}, {"epoch": 205, "train_loss": 2.313617929259936, "grad_norm": 0.05255087465047836, "test_error": 0.9}, {"epoch": 206, "train_loss": 2.3144146293401717, "grad_norm": 0.046252794563770294, "test_error": 0.9}, {"epoch": 207, "train_loss": 2.314130420446396, "grad_norm": 0.050174836069345474, "test_error": 0.9}, {"epoch": 208, "train_loss": 2.3138583332300184, "grad_norm": 0.019250676035881042, "test_error": 0.9}, {"epoch": 209, "train_loss": 2.3142378830512365, "grad_norm": 0.0479089617729187, "test_error": 0.9}, {"epoch": 210, "train_loss": 2.314115260799726, "grad_norm": 0.06230708584189415, "test_error": 0.9}, {"epoch": 211, "train_loss": 2.3141111361583073, "grad_norm": 0.045776285231113434, "test_error": 0.9}, {"epoch": 212, "train_loss": 2.3144749606847763, "grad_norm": 0.05520900711417198, "test_error": 0.9}, {"epoch": 213, "train_loss": 2.31444293487072, "grad_norm": 0.06592871993780136, "test_error": 0.9}, {"epoch": 214, "train_loss": 2.3138422596057255, "grad_norm": 0.038808200508356094, "test_error": 0.9}, {"epoch": 215, "train_loss": 2.313011489311854, "grad_norm": 0.046738866716623306, "test_error": 0.9}, {"epoch": 216, "train_loss": 2.31447748541832, "grad_norm": 0.0541803240776062, "test_error": 0.9}, {"epoch": 217, "train_loss": 2.3141770527362824, "grad_norm": 0.05552338436245918, "test_error": 0.9}, {"epoch": 218, "train_loss": 2.3144104689359666, "grad_norm": 0.030207542702555656, "test_error": 0.9}, {"epoch": 219, "train_loss": 2.3147911513646444, "grad_norm": 0.037823308259248734, "test_error": 0.9}, {"epoch": 220, "train_loss": 2.3137083849906923, "grad_norm": 0.0405905544757843, "test_error": 0.9}, {"epoch": 221, "train_loss": 2.314191946864128, "grad_norm": 0.05754794552922249, "test_error": 0.9}, {"epoch": 222, "train_loss": 2.314217716097832, "grad_norm": 0.04663730785250664, "test_error": 0.9}, {"epoch": 223, "train_loss": 2.313749482393265, "grad_norm": 0.041681163012981415, "test_error": 0.9}, {"epoch": 224, "train_loss": 2.3139569657643637, "grad_norm": 0.04533649981021881, "test_error": 0.9}, {"epoch": 225, "train_loss": 2.3141446328957875, "grad_norm": 0.03951912373304367, "test_error": 0.9}, {"epoch": 226, "train_loss": 2.314247150262197, "grad_norm": 0.040926918387413025, "test_error": 0.9}, {"epoch": 227, "train_loss": 2.3141010739008587, "grad_norm": 0.029212389141321182, "test_error": 0.9}, {"epoch": 228, "train_loss": 2.314513411641121, "grad_norm": 0.06756790727376938, "test_error": 0.9}, {"epoch": 229, "train_loss": 2.313781358043353, "grad_norm": 0.0245065838098526, "test_error": 0.9}, {"epoch": 230, "train_loss": 2.3136894788742066, "grad_norm": 0.04373485594987869, "test_error": 0.9}, {"epoch": 231, "train_loss": 2.3144668733278912, "grad_norm": 0.047122906893491745, "test_error": 0.9}, {"epoch": 232, "train_loss": 2.313954091588656, "grad_norm": 0.05242680385708809, "test_error": 0.9}, {"epoch": 233, "train_loss": 2.314487991174062, "grad_norm": 0.04611445590853691, "test_error": 0.9}, {"epoch": 234, "train_loss": 2.3141635428269702, "grad_norm": 0.018686790019273758, "test_error": 0.9}, {"epoch": 235, "train_loss": 2.313979033112526, "grad_norm": 0.04083998128771782, "test_error": 0.9}, {"epoch": 236, "train_loss": 2.3138363331158955, "grad_norm": 0.0647810623049736, "test_error": 0.9}, {"epoch": 237, "train_loss": 2.3135411169926328, "grad_norm": 0.03900256007909775, "test_error": 0.9}, {"epoch": 238, "train_loss": 2.314609457850456, "grad_norm": 0.02417033538222313, "test_error": 0.9}, {"epoch": 239, "train_loss": 2.3138912509679797, "grad_norm": 0.04271809384226799, "test_error": 0.9}, {"epoch": 240, "train_loss": 2.3138618924220404, "grad_norm": 0.05270272493362427, "test_error": 0.9}, {"epoch": 241, "train_loss": 2.3145582919915517, "grad_norm": 0.044399358332157135, "test_error": 0.9}, {"epoch": 242, "train_loss": 2.3142199505964913, "grad_norm": 0.032373592257499695, "test_error": 0.9}, {"epoch": 243, "train_loss": 2.3138294870058695, "grad_norm": 0.05464442819356918, "test_error": 0.9}, {"epoch": 244, "train_loss": 2.313762676914533, "grad_norm": 0.04164692759513855, "test_error": 0.9}, {"epoch": 245, "train_loss": 2.3139551635980604, "grad_norm": 0.03619525209069252, "test_error": 0.9}, {"epoch": 246, "train_loss": 2.3140975608825682, "grad_norm": 0.029171720147132874, "test_error": 0.9}, {"epoch": 247, "train_loss": 2.3142099351088206, "grad_norm": 0.06252092123031616, "test_error": 0.9}, {"epoch": 248, "train_loss": 2.3139655609528225, "grad_norm": 0.04479523003101349, "test_error": 0.9}, {"epoch": 249, "train_loss": 2.3142043172518414, "grad_norm": 0.05498836562037468, "test_error": 0.9}, {"epoch": 250, "train_loss": 2.3146420727173487, "grad_norm": 0.04302121326327324, "test_error": 0.9}, {"epoch": 251, "train_loss": 2.3139459689060846, "grad_norm": 0.0469716377556324, "test_error": 0.9}, {"epoch": 252, "train_loss": 2.3143389551639557, "grad_norm": 0.05180594325065613, "test_error": 0.9}, {"epoch": 253, "train_loss": 2.3141758948167164, "grad_norm": 0.04298475384712219, "test_error": 0.9}, {"epoch": 254, "train_loss": 2.31354697116216, "grad_norm": 0.053574126213788986, "test_error": 0.9}, {"epoch": 255, "train_loss": 2.31412684794267, "grad_norm": 0.04972526431083679, "test_error": 0.9}, {"epoch": 256, "train_loss": 2.314418363372485, "grad_norm": 0.037690941244363785, "test_error": 0.9}, {"epoch": 257, "train_loss": 2.3138978875080745, "grad_norm": 0.05740489438176155, "test_error": 0.9}, {"epoch": 258, "train_loss": 2.314074783484141, "grad_norm": 0.032300662249326706, "test_error": 0.9}, {"epoch": 259, "train_loss": 2.314803104917208, "grad_norm": 0.04120515659451485, "test_error": 0.9}, {"epoch": 260, "train_loss": 2.3141249699195225, "grad_norm": 0.04889100790023804, "test_error": 0.9}, {"epoch": 261, "train_loss": 2.314516591032346, "grad_norm": 0.05233537405729294, "test_error": 0.9}, {"epoch": 262, "train_loss": 2.313583469192187, "grad_norm": 0.056948039680719376, "test_error": 0.9}, {"epoch": 263, "train_loss": 2.3137158026297886, "grad_norm": 0.04837232083082199, "test_error": 0.9}, {"epoch": 264, "train_loss": 2.314483789841334, "grad_norm": 0.03441241756081581, "test_error": 0.9}, {"epoch": 265, "train_loss": 2.3136716109116873, "grad_norm": 0.06510607898235321, "test_error": 0.9}, {"epoch": 266, "train_loss": 2.3140839972496035, "grad_norm": 0.04573754593729973, "test_error": 0.9}, {"epoch": 267, "train_loss": 2.3141479747692744, "grad_norm": 0.030455075204372406, "test_error": 0.9}, {"epoch": 268, "train_loss": 2.314054706096649, "grad_norm": 0.04043365642428398, "test_error": 0.9}, {"epoch": 269, "train_loss": 2.3144251859982807, "grad_norm": 0.03587985411286354, "test_error": 0.9}, {"epoch": 270, "train_loss": 2.313649739185969, "grad_norm": 0.05172950029373169, "test_error": 0.9}, {"epoch": 271, "train_loss": 2.313957199136416, "grad_norm": 0.03536452353000641, "test_error": 0.9}, {"epoch": 272, "train_loss": 2.313661154349645, "grad_norm": 0.031898293644189835, "test_error": 0.9}, {"epoch": 273, "train_loss": 2.3142371502717336, "grad_norm": 0.06432252377271652, "test_error": 0.9}, {"epoch": 274, "train_loss": 2.3148925072352093, "grad_norm": 0.03974710404872894, "test_error": 0.9}, {"epoch": 275, "train_loss": 2.313761838197708, "grad_norm": 0.06114766001701355, "test_error": 0.9}, {"epoch": 276, "train_loss": 2.3142673556009927, "grad_norm": 0.044181063771247864, "test_error": 0.9}, {"epoch": 277, "train_loss": 2.313360992829005, "grad_norm": 0.05025599151849747, "test_error": 0.9}, {"epoch": 278, "train_loss": 2.313998567223549, "grad_norm": 0.04401310905814171, "test_error": 0.9}, {"epoch": 279, "train_loss": 2.3139894890785215, "grad_norm": 0.05122188478708267, "test_error": 0.9}, {"epoch": 280, "train_loss": 2.3142283427317936, "grad_norm": 0.04689570516347885, "test_error": 0.9}, {"epoch": 281, "train_loss": 2.313602455059687, "grad_norm": 0.059098634868860245, "test_error": 0.9}, {"epoch": 282, "train_loss": 2.3148995115756987, "grad_norm": 0.026717519387602806, "test_error": 0.9}, {"epoch": 283, "train_loss": 2.314301875869433, "grad_norm": 0.04955606907606125, "test_error": 0.9}, {"epoch": 284, "train_loss": 2.314274997830391, "grad_norm": 0.06307891756296158, "test_error": 0.9}, {"epoch": 285, "train_loss": 2.313479158560435, "grad_norm": 0.07286689430475235, "test_error": 0.9}, {"epoch": 286, "train_loss": 2.3144139751990638, "grad_norm": 0.04701966047286987, "test_error": 0.9}, {"epoch": 287, "train_loss": 2.3139113633235295, "grad_norm": 0.050114016979932785, "test_error": 0.9}, {"epoch": 288, "train_loss": 2.314147368510564, "grad_norm": 0.03278278186917305, "test_error": 0.9}, {"epoch": 289, "train_loss": 2.313953076561292, "grad_norm": 0.037604209035634995, "test_error": 0.9}, {"epoch": 290, "train_loss": 2.3144781181414924, "grad_norm": 0.06485308706760406, "test_error": 0.9}, {"epoch": 291, "train_loss": 2.313848219235738, "grad_norm": 0.04282667115330696, "test_error": 0.9}, {"epoch": 292, "train_loss": 2.3142603341738384, "grad_norm": 0.04937070608139038, "test_error": 0.9}, {"epoch": 293, "train_loss": 2.3139830576578775, "grad_norm": 0.0565357431769371, "test_error": 0.9}, {"epoch": 294, "train_loss": 2.3132693091630934, "grad_norm": 0.05490704998373985, "test_error": 0.9}, {"epoch": 295, "train_loss": 2.3142012083530425, "grad_norm": 0.037880804389715195, "test_error": 0.9}, {"epoch": 296, "train_loss": 2.314864903450012, "grad_norm": 0.03500241041183472, "test_error": 0.9}, {"epoch": 297, "train_loss": 2.314095502614975, "grad_norm": 0.027761144563555717, "test_error": 0.9}, {"epoch": 298, "train_loss": 2.31406747897466, "grad_norm": 0.0595671646296978, "test_error": 0.9}, {"epoch": 299, "train_loss": 2.313898560166359, "grad_norm": 0.04732779413461685, "test_error": 0.9}, {"epoch": 300, "train_loss": 2.314704582810402, "grad_norm": 0.03414043039083481, "test_error": 0.9}]}