{"argv": ["train.py", "--seed", "79", "--optimizer", "SGD", "--run_name", "sgd_0.1.json", "--output_path", "experiments/nonconvex_fmnist/sgd-0.1.json", "--dataset", "FMNIST", "--layer_sizes", "784", "100", "10", "--batch_size", "10", "--learning_rate", "0.1", "--weight_decay", "0.001", "--num_epochs", "300", "--download", "--device", "cuda"], "args": {"seed": 79, "optimizer": "SGD", "run_name": "sgd_0.1.json", "output_path": "experiments/nonconvex_fmnist/sgd-0.1.json", "device": "cuda", "dataset": "FMNIST", "dataset_root": "~/datasets/pytorch", "dataset_size": null, "download": true, "layer_sizes": [784, 100, 10], "batch_size": 10, "test_batch_size": 256, "learning_rate": 0.1, "weight_decay": 0.001, "warmup_learning_rate": 0.01, "num_warmup_epochs": 10, "num_outer_epochs": 100, "num_inner_epochs": 5, "inner_epoch_fraction": null, "choose_random_iterate": false, "num_epochs": 300}, "metrics": [{"epoch": 1, "train_loss": 0.5420943071478977, "grad_norm": 0.5275832414627075, "test_error": 0.16276666666666667}, {"epoch": 2, "train_loss": 0.43748232804735504, "grad_norm": 0.9271259307861328, "test_error": 0.16325}, {"epoch": 3, "train_loss": 0.41712465244011643, "grad_norm": 0.48897361755371094, "test_error": 0.1502}, {"epoch": 4, "train_loss": 0.4073733038651602, "grad_norm": 0.7570071220397949, "test_error": 0.15526666666666666}, {"epoch": 5, "train_loss": 0.4043611617858211, "grad_norm": 0.4470823407173157, "test_error": 0.14593333333333333}, {"epoch": 6, "train_loss": 0.3986778289983825, "grad_norm": 0.4511249363422394, "test_error": 0.13466666666666666}, {"epoch": 7, "train_loss": 0.3992205592691898, "grad_norm": 0.42031511664390564, "test_error": 0.13461666666666666}, {"epoch": 8, "train_loss": 0.3950886797525454, "grad_norm": 0.6429867744445801, "test_error": 0.15943333333333334}, {"epoch": 9, "train_loss": 0.3961128195902954, "grad_norm": 0.7782821655273438, "test_error": 0.14985}, {"epoch": 10, "train_loss": 0.3927739216821113, "grad_norm": 0.39794668555259705, "test_error": 0.13411666666666666}, {"epoch": 11, "train_loss": 0.3953778557977639, "grad_norm": 0.2883351743221283, "test_error": 0.12618333333333334}, {"epoch": 12, "train_loss": 0.3942234490228196, "grad_norm": 0.6640570163726807, "test_error": 0.14811666666666667}, {"epoch": 13, "train_loss": 0.3951143498364836, "grad_norm": 1.416106104850769, "test_error": 0.18061666666666668}, {"epoch": 14, "train_loss": 0.39329701352643315, "grad_norm": 0.6348654627799988, "test_error": 0.14493333333333333}, {"epoch": 15, "train_loss": 0.39181197092457054, "grad_norm": 0.3493209183216095, "test_error": 0.13218333333333335}, {"epoch": 16, "train_loss": 0.3902412475973445, "grad_norm": 0.7306709289550781, "test_error": 0.16141666666666668}, {"epoch": 17, "train_loss": 0.39294600118634604, "grad_norm": 0.4509167969226837, "test_error": 0.13063333333333332}, {"epoch": 18, "train_loss": 0.39107437351803914, "grad_norm": 0.4129250645637512, "test_error": 0.13366666666666666}, {"epoch": 19, "train_loss": 0.39166191703958125, "grad_norm": 0.43302392959594727, "test_error": 0.1384}, {"epoch": 20, "train_loss": 0.3884616687359133, "grad_norm": 0.7442203164100647, "test_error": 0.14651666666666666}, {"epoch": 21, "train_loss": 0.38977606552140787, "grad_norm": 0.6250728368759155, "test_error": 0.14255}, {"epoch": 22, "train_loss": 0.392671784531946, "grad_norm": 0.4966353476047516, "test_error": 0.13815}, {"epoch": 23, "train_loss": 0.390025147564942, "grad_norm": 0.7298458218574524, "test_error": 0.14356666666666668}, {"epoch": 24, "train_loss": 0.3906758307897641, "grad_norm": 0.7587222456932068, "test_error": 0.14721666666666666}, {"epoch": 25, "train_loss": 0.39051288649168175, "grad_norm": 0.4734320342540741, "test_error": 0.12776666666666667}, {"epoch": 26, "train_loss": 0.39083699007937683, "grad_norm": 0.4129338264465332, "test_error": 0.13128333333333334}, {"epoch": 27, "train_loss": 0.39003173882886766, "grad_norm": 0.5745792984962463, "test_error": 0.1523}, {"epoch": 28, "train_loss": 0.3905926550684962, "grad_norm": 0.9373698234558105, "test_error": 0.15686666666666665}, {"epoch": 29, "train_loss": 0.3879552956595241, "grad_norm": 0.49888989329338074, "test_error": 0.13191666666666665}, {"epoch": 30, "train_loss": 0.391903753932255, "grad_norm": 0.48004627227783203, "test_error": 0.14236666666666667}, {"epoch": 31, "train_loss": 0.3889356505702405, "grad_norm": 0.32106149196624756, "test_error": 0.13656666666666667}, {"epoch": 32, "train_loss": 0.38957553055335303, "grad_norm": 0.439276784658432, "test_error": 0.14016666666666666}, {"epoch": 33, "train_loss": 0.39099332893864874, "grad_norm": 0.27733516693115234, "test_error": 0.12573333333333334}, {"epoch": 34, "train_loss": 0.3899419135581702, "grad_norm": 0.44593626260757446, "test_error": 0.13596666666666668}, {"epoch": 35, "train_loss": 0.39267284545403286, "grad_norm": 0.5591133236885071, "test_error": 0.13338333333333333}, {"epoch": 36, "train_loss": 0.3890213469631659, "grad_norm": 0.4248672425746918, "test_error": 0.13686666666666666}, {"epoch": 37, "train_loss": 0.390243028004809, "grad_norm": 0.49894189834594727, "test_error": 0.13353333333333334}, {"epoch": 38, "train_loss": 0.39042420688826435, "grad_norm": 0.4139048159122467, "test_error": 0.1279}, {"epoch": 39, "train_loss": 0.39214873123557, "grad_norm": 0.4981011152267456, "test_error": 0.1441}, {"epoch": 40, "train_loss": 0.393139263753624, "grad_norm": 0.5296671390533447, "test_error": 0.1414}, {"epoch": 41, "train_loss": 0.39118446940288415, "grad_norm": 0.4075809717178345, "test_error": 0.13413333333333333}, {"epoch": 42, "train_loss": 0.3909207311302889, "grad_norm": 0.39519429206848145, "test_error": 0.12925}, {"epoch": 43, "train_loss": 0.391025196109976, "grad_norm": 0.32900142669677734, "test_error": 0.12825}, {"epoch": 44, "train_loss": 0.39161680250164743, "grad_norm": 0.5797594785690308, "test_error": 0.14483333333333334}, {"epoch": 45, "train_loss": 0.39269946361197317, "grad_norm": 0.36153411865234375, "test_error": 0.12723333333333334}, {"epoch": 46, "train_loss": 0.39159665440248015, "grad_norm": 0.45795363187789917, "test_error": 0.12863333333333332}, {"epoch": 47, "train_loss": 0.392021827533065, "grad_norm": 0.6560750603675842, "test_error": 0.14868333333333333}, {"epoch": 48, "train_loss": 0.39014879988789714, "grad_norm": 0.6206825971603394, "test_error": 0.15056666666666665}, {"epoch": 49, "train_loss": 0.39062327100821614, "grad_norm": 0.5220997929573059, "test_error": 0.13741666666666666}, {"epoch": 50, "train_loss": 0.39123141557288665, "grad_norm": 0.6865866184234619, "test_error": 0.15008333333333335}, {"epoch": 51, "train_loss": 0.3914625175520002, "grad_norm": 0.39473259449005127, "test_error": 0.12581666666666666}, {"epoch": 52, "train_loss": 0.39094405176956204, "grad_norm": 0.30157315731048584, "test_error": 0.12971666666666667}, {"epoch": 53, "train_loss": 0.391170298458077, "grad_norm": 1.0632745027542114, "test_error": 0.16371666666666668}, {"epoch": 54, "train_loss": 0.3925691116016824, "grad_norm": 0.771885871887207, "test_error": 0.15253333333333333}, {"epoch": 55, "train_loss": 0.3917218282225076, "grad_norm": 0.4817695915699005, "test_error": 0.13658333333333333}, {"epoch": 56, "train_loss": 0.390629535733955, "grad_norm": 0.3477118909358978, "test_error": 0.13605}, {"epoch": 57, "train_loss": 0.39203411092065893, "grad_norm": 0.2793918251991272, "test_error": 0.12705}, {"epoch": 58, "train_loss": 0.3895362725205875, "grad_norm": 0.46432462334632874, "test_error": 0.13456666666666667}, {"epoch": 59, "train_loss": 0.39109271685080604, "grad_norm": 0.3972916305065155, "test_error": 0.13098333333333334}, {"epoch": 60, "train_loss": 0.3882318630849865, "grad_norm": 0.6135167479515076, "test_error": 0.15146666666666667}, {"epoch": 61, "train_loss": 0.3912850732517739, "grad_norm": 0.5267255306243896, "test_error": 0.14275}, {"epoch": 62, "train_loss": 0.3926532627921551, "grad_norm": 0.2070302665233612, "test_error": 0.12473333333333333}, {"epoch": 63, "train_loss": 0.3903417690192194, "grad_norm": 0.3363168239593506, "test_error": 0.12953333333333333}, {"epoch": 64, "train_loss": 0.3918086894849548, "grad_norm": 0.33223673701286316, "test_error": 0.12603333333333333}, {"epoch": 65, "train_loss": 0.39090722507735093, "grad_norm": 0.4251146912574768, "test_error": 0.13556666666666667}, {"epoch": 66, "train_loss": 0.3899791342934283, "grad_norm": 0.32027167081832886, "test_error": 0.12763333333333332}, {"epoch": 67, "train_loss": 0.39130218773606856, "grad_norm": 0.42937198281288147, "test_error": 0.13618333333333332}, {"epoch": 68, "train_loss": 0.3889891998299475, "grad_norm": 1.4007693529129028, "test_error": 0.18931666666666666}, {"epoch": 69, "train_loss": 0.3901982720453913, "grad_norm": 0.8275062441825867, "test_error": 0.17101666666666668}, {"epoch": 70, "train_loss": 0.38899270576564593, "grad_norm": 0.7530574798583984, "test_error": 0.15483333333333332}, {"epoch": 71, "train_loss": 0.39109729444033775, "grad_norm": 0.6445646286010742, "test_error": 0.15036666666666668}, {"epoch": 72, "train_loss": 0.39209492029016835, "grad_norm": 0.5918183922767639, "test_error": 0.14088333333333333}, {"epoch": 73, "train_loss": 0.3901332250582054, "grad_norm": 1.6340970993041992, "test_error": 0.20815}, {"epoch": 74, "train_loss": 0.39252053216553756, "grad_norm": 1.3898823261260986, "test_error": 0.17766666666666667}, {"epoch": 75, "train_loss": 0.3897708026311205, "grad_norm": 0.448770672082901, "test_error": 0.13698333333333335}, {"epoch": 76, "train_loss": 0.38936008748815704, "grad_norm": 0.739712655544281, "test_error": 0.15495}, {"epoch": 77, "train_loss": 0.3892889421800307, "grad_norm": 0.38758888840675354, "test_error": 0.13908333333333334}, {"epoch": 78, "train_loss": 0.39093381574524877, "grad_norm": 2.1884610652923584, "test_error": 0.1941}, {"epoch": 79, "train_loss": 0.3893404014466796, "grad_norm": 0.8266458511352539, "test_error": 0.15861666666666666}, {"epoch": 80, "train_loss": 0.38866261556752335, "grad_norm": 0.7360816597938538, "test_error": 0.15733333333333333}, {"epoch": 81, "train_loss": 0.38931605402481123, "grad_norm": 0.6412752270698547, "test_error": 0.13431666666666667}, {"epoch": 82, "train_loss": 0.3898130322659078, "grad_norm": 0.7847789525985718, "test_error": 0.1525}, {"epoch": 83, "train_loss": 0.3896162286586283, "grad_norm": 0.4798146188259125, "test_error": 0.13463333333333333}, {"epoch": 84, "train_loss": 0.39015704597750056, "grad_norm": 0.3544592261314392, "test_error": 0.1292}, {"epoch": 85, "train_loss": 0.3910247797098321, "grad_norm": 0.32408860325813293, "test_error": 0.11998333333333333}, {"epoch": 86, "train_loss": 0.3883416096556854, "grad_norm": 0.4332217276096344, "test_error": 0.1333}, {"epoch": 87, "train_loss": 0.3888529905585262, "grad_norm": 0.4584599435329437, "test_error": 0.12613333333333332}, {"epoch": 88, "train_loss": 0.3909080252898469, "grad_norm": 0.37128931283950806, "test_error": 0.1311}, {"epoch": 89, "train_loss": 0.3900885404319658, "grad_norm": 0.3866041302680969, "test_error": 0.12711666666666666}, {"epoch": 90, "train_loss": 0.3915596731616339, "grad_norm": 0.41672027111053467, "test_error": 0.13298333333333334}, {"epoch": 91, "train_loss": 0.3905910270520253, "grad_norm": 0.3498649597167969, "test_error": 0.12871666666666667}, {"epoch": 92, "train_loss": 0.38993785827762134, "grad_norm": 0.45910507440567017, "test_error": 0.13751666666666668}, {"epoch": 93, "train_loss": 0.39129503761955614, "grad_norm": 0.5509611368179321, "test_error": 0.13995}, {"epoch": 94, "train_loss": 0.389937972121969, "grad_norm": 0.6993755102157593, "test_error": 0.15328333333333333}, {"epoch": 95, "train_loss": 0.3903509164995048, "grad_norm": 0.6524084210395813, "test_error": 0.1518}, {"epoch": 96, "train_loss": 0.38927682222988613, "grad_norm": 0.4226917326450348, "test_error": 0.13408333333333333}, {"epoch": 97, "train_loss": 0.38927172567881646, "grad_norm": 0.25725266337394714, "test_error": 0.12353333333333333}, {"epoch": 98, "train_loss": 0.3908306838211914, "grad_norm": 0.3884778618812561, "test_error": 0.13665}, {"epoch": 99, "train_loss": 0.3909036374173981, "grad_norm": 0.3498486280441284, "test_error": 0.13316666666666666}, {"epoch": 100, "train_loss": 0.39298760817782025, "grad_norm": 0.6784776449203491, "test_error": 0.14776666666666666}, {"epoch": 101, "train_loss": 0.39138371105977177, "grad_norm": 1.3774603605270386, "test_error": 0.20776666666666666}, {"epoch": 102, "train_loss": 0.3929931229423576, "grad_norm": 0.4852150082588196, "test_error": 0.13593333333333332}, {"epoch": 103, "train_loss": 0.3937012954571207, "grad_norm": 0.47343185544013977, "test_error": 0.13415}, {"epoch": 104, "train_loss": 0.388832036240104, "grad_norm": 0.7717893123626709, "test_error": 0.1506}, {"epoch": 105, "train_loss": 0.3900315643782572, "grad_norm": 0.5586504936218262, "test_error": 0.1508}, {"epoch": 106, "train_loss": 0.38865935148120234, "grad_norm": 0.4138166606426239, "test_error": 0.1339}, {"epoch": 107, "train_loss": 0.38925040609494316, "grad_norm": 0.6630775332450867, "test_error": 0.1538}, {"epoch": 108, "train_loss": 0.39096022524141394, "grad_norm": 0.6878789663314819, "test_error": 0.14915}, {"epoch": 109, "train_loss": 0.3895279636157696, "grad_norm": 0.3978099822998047, "test_error": 0.12803333333333333}, {"epoch": 110, "train_loss": 0.38971309920664254, "grad_norm": 0.7257917523384094, "test_error": 0.15433333333333332}, {"epoch": 111, "train_loss": 0.3896347986162485, "grad_norm": 0.4808521270751953, "test_error": 0.13775}, {"epoch": 112, "train_loss": 0.39171581996391375, "grad_norm": 0.4258550703525543, "test_error": 0.13395}, {"epoch": 113, "train_loss": 0.3894817920842518, "grad_norm": 0.791840136051178, "test_error": 0.1521}, {"epoch": 114, "train_loss": 0.3906934618659628, "grad_norm": 0.3297291398048401, "test_error": 0.12858333333333333}, {"epoch": 115, "train_loss": 0.39318363486525293, "grad_norm": 0.8322566747665405, "test_error": 0.16346666666666668}, {"epoch": 116, "train_loss": 0.3934930024495892, "grad_norm": 0.4050630033016205, "test_error": 0.13001666666666667}, {"epoch": 117, "train_loss": 0.3896929617801992, "grad_norm": 0.5589144825935364, "test_error": 0.14286666666666667}, {"epoch": 118, "train_loss": 0.3884906794304261, "grad_norm": 0.5226315259933472, "test_error": 0.13365}, {"epoch": 119, "train_loss": 0.3908490552608467, "grad_norm": 0.7391055822372437, "test_error": 0.15273333333333333}, {"epoch": 120, "train_loss": 0.39144230641657485, "grad_norm": 0.4983246326446533, "test_error": 0.13548333333333334}, {"epoch": 121, "train_loss": 0.39086561468049574, "grad_norm": 0.5325175523757935, "test_error": 0.141}, {"epoch": 122, "train_loss": 0.3904190869695352, "grad_norm": 0.4516431987285614, "test_error": 0.13743333333333332}, {"epoch": 123, "train_loss": 0.3919582013687468, "grad_norm": 0.4062866270542145, "test_error": 0.12946666666666667}, {"epoch": 124, "train_loss": 0.38948656603243825, "grad_norm": 0.38330942392349243, "test_error": 0.12826666666666667}, {"epoch": 125, "train_loss": 0.3901788153273325, "grad_norm": 0.34052225947380066, "test_error": 0.12715}, {"epoch": 126, "train_loss": 0.392831141802948, "grad_norm": 0.2822364270687103, "test_error": 0.12036666666666666}, {"epoch": 127, "train_loss": 0.38777149818882267, "grad_norm": 0.5711161494255066, "test_error": 0.1358}, {"epoch": 128, "train_loss": 0.39248012552565587, "grad_norm": 1.3301934003829956, "test_error": 0.17301666666666668}, {"epoch": 129, "train_loss": 0.3898874748475694, "grad_norm": 0.3269440829753876, "test_error": 0.1289}, {"epoch": 130, "train_loss": 0.38969510719055933, "grad_norm": 0.28657060861587524, "test_error": 0.12808333333333333}, {"epoch": 131, "train_loss": 0.3920617007984741, "grad_norm": 0.4680584967136383, "test_error": 0.14158333333333334}, {"epoch": 132, "train_loss": 0.3894827806147708, "grad_norm": 0.632483184337616, "test_error": 0.15318333333333334}, {"epoch": 133, "train_loss": 0.389940679111518, "grad_norm": 0.5768118500709534, "test_error": 0.13805}, {"epoch": 134, "train_loss": 0.39140058917016723, "grad_norm": 0.3700485825538635, "test_error": 0.12545}, {"epoch": 135, "train_loss": 0.3915311115142734, "grad_norm": 0.4353892207145691, "test_error": 0.13746666666666665}, {"epoch": 136, "train_loss": 0.39028434949201374, "grad_norm": 0.4968585968017578, "test_error": 0.13248333333333334}, {"epoch": 137, "train_loss": 0.38856223991311467, "grad_norm": 0.3469676673412323, "test_error": 0.13128333333333334}, {"epoch": 138, "train_loss": 0.39015888577889807, "grad_norm": 0.4568691849708557, "test_error": 0.14043333333333333}, {"epoch": 139, "train_loss": 0.3895730158248916, "grad_norm": 0.49033278226852417, "test_error": 0.13271666666666668}, {"epoch": 140, "train_loss": 0.3899541604059438, "grad_norm": 0.5253512859344482, "test_error": 0.14963333333333334}, {"epoch": 141, "train_loss": 0.38933975390170233, "grad_norm": 0.3087352514266968, "test_error": 0.12535}, {"epoch": 142, "train_loss": 0.39112070679781025, "grad_norm": 0.49699851870536804, "test_error": 0.13798333333333335}, {"epoch": 143, "train_loss": 0.3895276839774257, "grad_norm": 0.48365092277526855, "test_error": 0.13555}, {"epoch": 144, "train_loss": 0.38923254808032653, "grad_norm": 0.6879203915596008, "test_error": 0.14411666666666667}, {"epoch": 145, "train_loss": 0.389835051019288, "grad_norm": 0.5155470967292786, "test_error": 0.13445}, {"epoch": 146, "train_loss": 0.38939373967579255, "grad_norm": 0.36276328563690186, "test_error": 0.12816666666666668}, {"epoch": 147, "train_loss": 0.39124466431148663, "grad_norm": 0.6531572937965393, "test_error": 0.1606}, {"epoch": 148, "train_loss": 0.38960994105995633, "grad_norm": 0.41174525022506714, "test_error": 0.13536666666666666}, {"epoch": 149, "train_loss": 0.3874343976407157, "grad_norm": 0.624472975730896, "test_error": 0.14411666666666667}, {"epoch": 150, "train_loss": 0.38750490242172964, "grad_norm": 1.0148534774780273, "test_error": 0.16813333333333333}, {"epoch": 151, "train_loss": 0.3898981437860057, "grad_norm": 0.3572683036327362, "test_error": 0.12606666666666666}, {"epoch": 152, "train_loss": 0.390629648889415, "grad_norm": 0.3606880009174347, "test_error": 0.13183333333333333}, {"epoch": 153, "train_loss": 0.39010298636928203, "grad_norm": 0.3462609052658081, "test_error": 0.12453333333333333}, {"epoch": 154, "train_loss": 0.38938142313497764, "grad_norm": 0.292809396982193, "test_error": 0.12828333333333333}, {"epoch": 155, "train_loss": 0.3895138032353328, "grad_norm": 0.6492844820022583, "test_error": 0.159}, {"epoch": 156, "train_loss": 0.39045516635473665, "grad_norm": 0.260020911693573, "test_error": 0.1203}, {"epoch": 157, "train_loss": 0.3897480689691535, "grad_norm": 0.5611857771873474, "test_error": 0.1311}, {"epoch": 158, "train_loss": 0.3882135530694698, "grad_norm": 0.40637701749801636, "test_error": 0.12921666666666667}, {"epoch": 159, "train_loss": 0.38985875216010024, "grad_norm": 0.49960047006607056, "test_error": 0.14121666666666666}, {"epoch": 160, "train_loss": 0.39151287990474765, "grad_norm": 0.31780755519866943, "test_error": 0.12436666666666667}, {"epoch": 161, "train_loss": 0.3904833859129188, "grad_norm": 0.521332323551178, "test_error": 0.15558333333333332}, {"epoch": 162, "train_loss": 0.38887580650897385, "grad_norm": 0.6067066192626953, "test_error": 0.14658333333333334}, {"epoch": 163, "train_loss": 0.38925219711641934, "grad_norm": 0.41835156083106995, "test_error": 0.12936666666666666}, {"epoch": 164, "train_loss": 0.39000711666443383, "grad_norm": 0.3044334948062897, "test_error": 0.12443333333333334}, {"epoch": 165, "train_loss": 0.38959070465069573, "grad_norm": 0.3814884126186371, "test_error": 0.13166666666666665}, {"epoch": 166, "train_loss": 0.3902178590897238, "grad_norm": 0.6096449494361877, "test_error": 0.14385}, {"epoch": 167, "train_loss": 0.38924090412973117, "grad_norm": 0.5865360498428345, "test_error": 0.13721666666666665}, {"epoch": 168, "train_loss": 0.38944307570217646, "grad_norm": 0.5435515642166138, "test_error": 0.13693333333333332}, {"epoch": 169, "train_loss": 0.39209878706303425, "grad_norm": 0.39152583479881287, "test_error": 0.13058333333333333}, {"epoch": 170, "train_loss": 0.38892652043544995, "grad_norm": 0.5006895661354065, "test_error": 0.13775}, {"epoch": 171, "train_loss": 0.38958294203000454, "grad_norm": 0.4648198187351227, "test_error": 0.13953333333333334}, {"epoch": 172, "train_loss": 0.3882715978270086, "grad_norm": 0.6149397492408752, "test_error": 0.13973333333333332}, {"epoch": 173, "train_loss": 0.388393429907, "grad_norm": 0.36747950315475464, "test_error": 0.13603333333333334}, {"epoch": 174, "train_loss": 0.38985123102809305, "grad_norm": 0.6441072225570679, "test_error": 0.154}, {"epoch": 175, "train_loss": 0.3892586831069396, "grad_norm": 0.4269694685935974, "test_error": 0.13886666666666667}, {"epoch": 176, "train_loss": 0.38866444674192463, "grad_norm": 0.3555591106414795, "test_error": 0.1247}, {"epoch": 177, "train_loss": 0.38902733848569915, "grad_norm": 0.48598989844322205, "test_error": 0.1338}, {"epoch": 178, "train_loss": 0.38848654740214505, "grad_norm": 0.5338339805603027, "test_error": 0.14393333333333333}, {"epoch": 179, "train_loss": 0.3907401003205838, "grad_norm": 0.31543025374412537, "test_error": 0.1313}, {"epoch": 180, "train_loss": 0.3901071859997076, "grad_norm": 0.3802550137042999, "test_error": 0.13585}, {"epoch": 181, "train_loss": 0.38812362810082657, "grad_norm": 0.4291114807128906, "test_error": 0.13678333333333334}, {"epoch": 182, "train_loss": 0.38925023325214475, "grad_norm": 0.2793951630592346, "test_error": 0.12231666666666667}, {"epoch": 183, "train_loss": 0.38957703875098376, "grad_norm": 1.027001142501831, "test_error": 0.1753}, {"epoch": 184, "train_loss": 0.3885609433851593, "grad_norm": 0.8189252614974976, "test_error": 0.15036666666666668}, {"epoch": 185, "train_loss": 0.39003706896041207, "grad_norm": 0.6042771339416504, "test_error": 0.15635}, {"epoch": 186, "train_loss": 0.3898116141807598, "grad_norm": 0.4467565417289734, "test_error": 0.13288333333333333}, {"epoch": 187, "train_loss": 0.388569852060716, "grad_norm": 0.4626690149307251, "test_error": 0.13496666666666668}, {"epoch": 188, "train_loss": 0.38767567004073256, "grad_norm": 0.5988017320632935, "test_error": 0.1449}, {"epoch": 189, "train_loss": 0.3913395653264209, "grad_norm": 0.5025448203086853, "test_error": 0.13603333333333334}, {"epoch": 190, "train_loss": 0.3881859930989643, "grad_norm": 0.3079245686531067, "test_error": 0.12318333333333334}, {"epoch": 191, "train_loss": 0.3907714221095666, "grad_norm": 0.5112043619155884, "test_error": 0.13738333333333333}, {"epoch": 192, "train_loss": 0.3887347059608437, "grad_norm": 0.5389614105224609, "test_error": 0.13595}, {"epoch": 193, "train_loss": 0.3898605035058378, "grad_norm": 0.2549384832382202, "test_error": 0.12241666666666666}, {"epoch": 194, "train_loss": 0.38831500078458336, "grad_norm": 0.3355070948600769, "test_error": 0.12423333333333333}, {"epoch": 195, "train_loss": 0.3889811859379988, "grad_norm": 0.4771876037120819, "test_error": 0.1329}, {"epoch": 196, "train_loss": 0.39002735875003663, "grad_norm": 0.28442636132240295, "test_error": 0.12313333333333333}, {"epoch": 197, "train_loss": 0.38910076922069614, "grad_norm": 0.532882571220398, "test_error": 0.13765}, {"epoch": 198, "train_loss": 0.388781024105226, "grad_norm": 0.4133410155773163, "test_error": 0.14705}, {"epoch": 199, "train_loss": 0.3898497580214559, "grad_norm": 0.777592658996582, "test_error": 0.15246666666666667}, {"epoch": 200, "train_loss": 0.3918948162556626, "grad_norm": 0.8354589343070984, "test_error": 0.16285}, {"epoch": 201, "train_loss": 0.38977825613863143, "grad_norm": 0.49369826912879944, "test_error": 0.13486666666666666}, {"epoch": 202, "train_loss": 0.39120576639166876, "grad_norm": 0.28578370809555054, "test_error": 0.12363333333333333}, {"epoch": 203, "train_loss": 0.3898671075273305, "grad_norm": 0.6798416972160339, "test_error": 0.15531666666666666}, {"epoch": 204, "train_loss": 0.391764186264559, "grad_norm": 0.6713619828224182, "test_error": 0.1409}, {"epoch": 205, "train_loss": 0.39036136123737863, "grad_norm": 0.40301498770713806, "test_error": 0.13333333333333333}, {"epoch": 206, "train_loss": 0.39002377968654034, "grad_norm": 0.5356987714767456, "test_error": 0.1403}, {"epoch": 207, "train_loss": 0.38970926438489306, "grad_norm": 0.46230921149253845, "test_error": 0.13025}, {"epoch": 208, "train_loss": 0.39053313827165403, "grad_norm": 0.6446715593338013, "test_error": 0.14395}, {"epoch": 209, "train_loss": 0.3912493147675414, "grad_norm": 0.8645926117897034, "test_error": 0.16455}, {"epoch": 210, "train_loss": 0.3900959061284084, "grad_norm": 0.6983869671821594, "test_error": 0.14425}, {"epoch": 211, "train_loss": 0.3879195116296566, "grad_norm": 0.5815104842185974, "test_error": 0.14535}, {"epoch": 212, "train_loss": 0.3895334770718279, "grad_norm": 0.3452666699886322, "test_error": 0.13055}, {"epoch": 213, "train_loss": 0.38888115393083234, "grad_norm": 3.4727978706359863, "test_error": 0.25743333333333335}, {"epoch": 214, "train_loss": 0.3903781076701513, "grad_norm": 0.6097684502601624, "test_error": 0.14771666666666666}, {"epoch": 215, "train_loss": 0.38780287974234673, "grad_norm": 0.36778244376182556, "test_error": 0.12565}, {"epoch": 216, "train_loss": 0.38885211462026925, "grad_norm": 0.8138757944107056, "test_error": 0.16016666666666668}, {"epoch": 217, "train_loss": 0.390625891861661, "grad_norm": 0.24659644067287445, "test_error": 0.12245}, {"epoch": 218, "train_loss": 0.3902763934286777, "grad_norm": 0.2693093419075012, "test_error": 0.12791666666666668}, {"epoch": 219, "train_loss": 0.3904793862917771, "grad_norm": 0.3523712158203125, "test_error": 0.12803333333333333}, {"epoch": 220, "train_loss": 0.39259294627211055, "grad_norm": 0.5285139083862305, "test_error": 0.13891666666666666}, {"epoch": 221, "train_loss": 0.38875893761147745, "grad_norm": 0.5515377521514893, "test_error": 0.1355}, {"epoch": 222, "train_loss": 0.39136652697832325, "grad_norm": 1.0557129383087158, "test_error": 0.15785}, {"epoch": 223, "train_loss": 0.39161779982519024, "grad_norm": 0.4962869882583618, "test_error": 0.12828333333333333}, {"epoch": 224, "train_loss": 0.39032799859484657, "grad_norm": 0.3885834813117981, "test_error": 0.13246666666666668}, {"epoch": 225, "train_loss": 0.3903267063116655, "grad_norm": 0.29371967911720276, "test_error": 0.12935}, {"epoch": 226, "train_loss": 0.38956804819397317, "grad_norm": 0.6192376613616943, "test_error": 0.14463333333333334}, {"epoch": 227, "train_loss": 0.3896043658875472, "grad_norm": 0.3253045380115509, "test_error": 0.13128333333333334}, {"epoch": 228, "train_loss": 0.39130511194017403, "grad_norm": 0.3082221746444702, "test_error": 0.13106666666666666}, {"epoch": 229, "train_loss": 0.3909396154168838, "grad_norm": 0.5615336298942566, "test_error": 0.1446}, {"epoch": 230, "train_loss": 0.38980618671762446, "grad_norm": 0.1666860580444336, "test_error": 0.11511666666666667}, {"epoch": 231, "train_loss": 0.3897882522775326, "grad_norm": 0.33892709016799927, "test_error": 0.13243333333333332}, {"epoch": 232, "train_loss": 0.38772448415883504, "grad_norm": 1.605454683303833, "test_error": 0.20113333333333333}, {"epoch": 233, "train_loss": 0.39143227059658, "grad_norm": 0.3130069673061371, "test_error": 0.12535}, {"epoch": 234, "train_loss": 0.3895866786768117, "grad_norm": 0.4172333776950836, "test_error": 0.13318333333333332}, {"epoch": 235, "train_loss": 0.3913701704838313, "grad_norm": 0.44467392563819885, "test_error": 0.12551666666666667}, {"epoch": 236, "train_loss": 0.39064566321050126, "grad_norm": 0.5387803912162781, "test_error": 0.13158333333333333}, {"epoch": 237, "train_loss": 0.3873782589272596, "grad_norm": 0.2530573010444641, "test_error": 0.11856666666666667}, {"epoch": 238, "train_loss": 0.3913879702463746, "grad_norm": 0.3337167203426361, "test_error": 0.13206666666666667}, {"epoch": 239, "train_loss": 0.38883348083170133, "grad_norm": 0.8770385980606079, "test_error": 0.15626666666666666}, {"epoch": 240, "train_loss": 0.38970834798524934, "grad_norm": 0.4686277210712433, "test_error": 0.14691666666666667}, {"epoch": 241, "train_loss": 0.3913436331566578, "grad_norm": 1.0669066905975342, "test_error": 0.18561666666666668}, {"epoch": 242, "train_loss": 0.386981544689741, "grad_norm": 1.0043282508850098, "test_error": 0.16755}, {"epoch": 243, "train_loss": 0.38697309559288745, "grad_norm": 0.42262953519821167, "test_error": 0.13223333333333334}, {"epoch": 244, "train_loss": 0.3884568609981798, "grad_norm": 0.4836060404777527, "test_error": 0.13361666666666666}, {"epoch": 245, "train_loss": 0.390694822832942, "grad_norm": 0.587562084197998, "test_error": 0.14985}, {"epoch": 246, "train_loss": 0.38997384983762945, "grad_norm": 0.5288928151130676, "test_error": 0.14221666666666666}, {"epoch": 247, "train_loss": 0.38811920942622236, "grad_norm": 0.7119971513748169, "test_error": 0.14258333333333334}, {"epoch": 248, "train_loss": 0.3910487572700561, "grad_norm": 0.5698984265327454, "test_error": 0.13443333333333332}, {"epoch": 249, "train_loss": 0.3898017688327624, "grad_norm": 0.4017691910266876, "test_error": 0.13048333333333334}, {"epoch": 250, "train_loss": 0.39084936063263254, "grad_norm": 0.577515184879303, "test_error": 0.1463}, {"epoch": 251, "train_loss": 0.3908566759621802, "grad_norm": 0.3219761550426483, "test_error": 0.1248}, {"epoch": 252, "train_loss": 0.39049591384094673, "grad_norm": 0.8587251305580139, "test_error": 0.15873333333333334}, {"epoch": 253, "train_loss": 0.3888132515405305, "grad_norm": 0.33492082357406616, "test_error": 0.12813333333333332}, {"epoch": 254, "train_loss": 0.39192945921995365, "grad_norm": 0.3731723725795746, "test_error": 0.12426666666666666}, {"epoch": 255, "train_loss": 0.38822225062161064, "grad_norm": 0.29306545853614807, "test_error": 0.1214}, {"epoch": 256, "train_loss": 0.3886807963141085, "grad_norm": 0.5804573893547058, "test_error": 0.13683333333333333}, {"epoch": 257, "train_loss": 0.39062376191451526, "grad_norm": 0.3761570155620575, "test_error": 0.12483333333333334}, {"epoch": 258, "train_loss": 0.39133687306117887, "grad_norm": 0.31862619519233704, "test_error": 0.1272}, {"epoch": 259, "train_loss": 0.3914801682513207, "grad_norm": 0.3290382921695709, "test_error": 0.12455}, {"epoch": 260, "train_loss": 0.3892190588406908, "grad_norm": 0.2950567901134491, "test_error": 0.12753333333333333}, {"epoch": 261, "train_loss": 0.3899522403384714, "grad_norm": 0.44300907850265503, "test_error": 0.1309}, {"epoch": 262, "train_loss": 0.39001689428277314, "grad_norm": 0.5289148092269897, "test_error": 0.14835}, {"epoch": 263, "train_loss": 0.3882602804962856, "grad_norm": 0.30134642124176025, "test_error": 0.12661666666666666}, {"epoch": 264, "train_loss": 0.39096484446843777, "grad_norm": 0.36268240213394165, "test_error": 0.13015}, {"epoch": 265, "train_loss": 0.38826152271653214, "grad_norm": 0.6189036965370178, "test_error": 0.14585}, {"epoch": 266, "train_loss": 0.38842617204785346, "grad_norm": 0.4813685417175293, "test_error": 0.13453333333333334}, {"epoch": 267, "train_loss": 0.39211714653725116, "grad_norm": 0.29683351516723633, "test_error": 0.125}, {"epoch": 268, "train_loss": 0.3870334903585802, "grad_norm": 0.3719545900821686, "test_error": 0.1264}, {"epoch": 269, "train_loss": 0.3890757553491276, "grad_norm": 0.6119221448898315, "test_error": 0.14018333333333333}, {"epoch": 270, "train_loss": 0.38916517118504274, "grad_norm": 0.34689971804618835, "test_error": 0.13586666666666666}, {"epoch": 271, "train_loss": 0.3892192935287797, "grad_norm": 0.3543137013912201, "test_error": 0.12546666666666667}, {"epoch": 272, "train_loss": 0.3886345046799009, "grad_norm": 0.3197563588619232, "test_error": 0.12848333333333334}, {"epoch": 273, "train_loss": 0.3893853270051962, "grad_norm": 0.2547833323478699, "test_error": 0.12131666666666667}, {"epoch": 274, "train_loss": 0.39038821947442676, "grad_norm": 0.3253733813762665, "test_error": 0.12605}, {"epoch": 275, "train_loss": 0.3900396213066609, "grad_norm": 0.7401440143585205, "test_error": 0.1486}, {"epoch": 276, "train_loss": 0.39102859762497244, "grad_norm": 0.265945166349411, "test_error": 0.11845}, {"epoch": 277, "train_loss": 0.3911958736107529, "grad_norm": 0.383801132440567, "test_error": 0.12845}, {"epoch": 278, "train_loss": 0.3904110790951721, "grad_norm": 0.47262972593307495, "test_error": 0.13466666666666666}, {"epoch": 279, "train_loss": 0.38808610221914325, "grad_norm": 0.46500784158706665, "test_error": 0.1286}, {"epoch": 280, "train_loss": 0.3919328848471244, "grad_norm": 0.28418558835983276, "test_error": 0.12823333333333334}, {"epoch": 281, "train_loss": 0.3908624371184657, "grad_norm": 0.3911951184272766, "test_error": 0.13281666666666667}, {"epoch": 282, "train_loss": 0.3888921898789704, "grad_norm": 0.9996836185455322, "test_error": 0.16021666666666667}, {"epoch": 283, "train_loss": 0.3864182318667687, "grad_norm": 0.44729775190353394, "test_error": 0.1392}, {"epoch": 284, "train_loss": 0.39164970980173286, "grad_norm": 0.18087218701839447, "test_error": 0.11811666666666666}, {"epoch": 285, "train_loss": 0.3877251874737752, "grad_norm": 0.402465283870697, "test_error": 0.13201666666666667}, {"epoch": 286, "train_loss": 0.39117867975107706, "grad_norm": 0.5259647965431213, "test_error": 0.14133333333333334}, {"epoch": 287, "train_loss": 0.39012432674931674, "grad_norm": 0.3399793207645416, "test_error": 0.13273333333333334}, {"epoch": 288, "train_loss": 0.3896502940626039, "grad_norm": 0.37470492720603943, "test_error": 0.13591666666666666}, {"epoch": 289, "train_loss": 0.39167482914748447, "grad_norm": 0.606282651424408, "test_error": 0.13701666666666668}, {"epoch": 290, "train_loss": 0.3888438766151667, "grad_norm": 0.5751891732215881, "test_error": 0.14498333333333333}, {"epoch": 291, "train_loss": 0.38837636813955034, "grad_norm": 0.5421026945114136, "test_error": 0.1414}, {"epoch": 292, "train_loss": 0.39067941241263177, "grad_norm": 0.4248062074184418, "test_error": 0.1313}, {"epoch": 293, "train_loss": 0.39053755012263236, "grad_norm": 0.2616187036037445, "test_error": 0.11788333333333334}, {"epoch": 294, "train_loss": 0.38926344614786407, "grad_norm": 0.4207864999771118, "test_error": 0.14026666666666668}, {"epoch": 295, "train_loss": 0.38879128539919233, "grad_norm": 0.6791868805885315, "test_error": 0.14653333333333332}, {"epoch": 296, "train_loss": 0.39059530118263014, "grad_norm": 0.8379917740821838, "test_error": 0.15458333333333332}, {"epoch": 297, "train_loss": 0.3916634311885573, "grad_norm": 0.30459466576576233, "test_error": 0.122}, {"epoch": 298, "train_loss": 0.3877280400570792, "grad_norm": 0.33737558126449585, "test_error": 0.1285}, {"epoch": 299, "train_loss": 0.38856941543651435, "grad_norm": 0.3228660225868225, "test_error": 0.12486666666666667}, {"epoch": 300, "train_loss": 0.39055410101582916, "grad_norm": 0.6565641760826111, "test_error": 0.15606666666666666}]}