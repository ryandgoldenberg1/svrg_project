{"argv": ["train.py", "--seed", "79", "--optimizer", "SGD", "--run_name", "sgd-0.01.json", "--output_path", "experiments/nonconvex_mnist/sgd-0.01.json", "--dataset", "MNIST", "--layer_sizes", "784", "100", "10", "--batch_size", "10", "--learning_rate", "0.01", "--weight_decay", "0.001", "--num_epochs", "300"], "args": {"seed": 79, "optimizer": "SGD", "run_name": "sgd-0.01.json", "output_path": "experiments/nonconvex_mnist/sgd-0.01.json", "device": "cpu", "dataset": "MNIST", "dataset_root": "~/datasets/pytorch", "dataset_size": null, "download": false, "layer_sizes": [784, 100, 10], "batch_size": 10, "test_batch_size": 256, "learning_rate": 0.01, "weight_decay": 0.001, "warmup_learning_rate": 0.01, "num_warmup_epochs": 10, "num_outer_epochs": 100, "num_inner_epochs": 5, "inner_epoch_fraction": null, "choose_random_iterate": false, "num_epochs": 300}, "metrics": [{"epoch": 1, "train_loss": 0.5188348725363612, "grad_norm": 0.27893590927124023, "test_error": 0.083}, {"epoch": 2, "train_loss": 0.27609494199355444, "grad_norm": 0.14596016705036163, "test_error": 0.0665}, {"epoch": 3, "train_loss": 0.2256361613770326, "grad_norm": 0.09488573670387268, "test_error": 0.0533}, {"epoch": 4, "train_loss": 0.19209197304494835, "grad_norm": 0.14906661212444305, "test_error": 0.0477}, {"epoch": 5, "train_loss": 0.16881416751731498, "grad_norm": 0.14764176309108734, "test_error": 0.0448}, {"epoch": 6, "train_loss": 0.15236349572928157, "grad_norm": 0.10120082646608353, "test_error": 0.0407}, {"epoch": 7, "train_loss": 0.14004998097231147, "grad_norm": 0.10506049543619156, "test_error": 0.0385}, {"epoch": 8, "train_loss": 0.13009901730502801, "grad_norm": 0.08830109983682632, "test_error": 0.0368}, {"epoch": 9, "train_loss": 0.12227553170069587, "grad_norm": 0.1602432131767273, "test_error": 0.035}, {"epoch": 10, "train_loss": 0.11544265067468708, "grad_norm": 0.14196790754795074, "test_error": 0.035}, {"epoch": 11, "train_loss": 0.1099584845637631, "grad_norm": 0.10313492268323898, "test_error": 0.0317}, {"epoch": 12, "train_loss": 0.1053505414306807, "grad_norm": 0.0952504351735115, "test_error": 0.0306}, {"epoch": 13, "train_loss": 0.10171714181736267, "grad_norm": 0.09217458218336105, "test_error": 0.0304}, {"epoch": 14, "train_loss": 0.09794010124528238, "grad_norm": 0.09196823835372925, "test_error": 0.0304}, {"epoch": 15, "train_loss": 0.0949662501658313, "grad_norm": 0.12128445506095886, "test_error": 0.0297}, {"epoch": 16, "train_loss": 0.0923316773425322, "grad_norm": 0.07408025115728378, "test_error": 0.0295}, {"epoch": 17, "train_loss": 0.09011686879384798, "grad_norm": 0.059701066464185715, "test_error": 0.0278}, {"epoch": 18, "train_loss": 0.08792776587452196, "grad_norm": 0.060518454760313034, "test_error": 0.0277}, {"epoch": 19, "train_loss": 0.08626687217884076, "grad_norm": 0.09741488844156265, "test_error": 0.0274}, {"epoch": 20, "train_loss": 0.08446959152957424, "grad_norm": 0.05799280107021332, "test_error": 0.027}, {"epoch": 21, "train_loss": 0.08328480746024676, "grad_norm": 0.06322318315505981, "test_error": 0.0261}, {"epoch": 22, "train_loss": 0.08199693694214026, "grad_norm": 0.07852718979120255, "test_error": 0.0269}, {"epoch": 23, "train_loss": 0.08098262119910214, "grad_norm": 0.06258217245340347, "test_error": 0.0262}, {"epoch": 24, "train_loss": 0.07973500902712112, "grad_norm": 0.08366163074970245, "test_error": 0.0259}, {"epoch": 25, "train_loss": 0.07861718949023634, "grad_norm": 0.05265961214900017, "test_error": 0.0252}, {"epoch": 26, "train_loss": 0.07793415325565729, "grad_norm": 0.05250491946935654, "test_error": 0.0258}, {"epoch": 27, "train_loss": 0.07687314748634042, "grad_norm": 0.045416928827762604, "test_error": 0.0245}, {"epoch": 28, "train_loss": 0.07628800307683802, "grad_norm": 0.043831173330545425, "test_error": 0.0246}, {"epoch": 29, "train_loss": 0.07540303324599518, "grad_norm": 0.0694064199924469, "test_error": 0.0249}, {"epoch": 30, "train_loss": 0.07480536851777772, "grad_norm": 0.051165610551834106, "test_error": 0.0239}, {"epoch": 31, "train_loss": 0.07427465272954821, "grad_norm": 0.08829507231712341, "test_error": 0.0244}, {"epoch": 32, "train_loss": 0.07393034062092192, "grad_norm": 0.08786027133464813, "test_error": 0.025}, {"epoch": 33, "train_loss": 0.07348579691478517, "grad_norm": 0.0794818326830864, "test_error": 0.0242}, {"epoch": 34, "train_loss": 0.0729535604896179, "grad_norm": 0.04323921725153923, "test_error": 0.0244}, {"epoch": 35, "train_loss": 0.07260565892547796, "grad_norm": 0.08027076721191406, "test_error": 0.025}, {"epoch": 36, "train_loss": 0.07186006721960923, "grad_norm": 0.10024474561214447, "test_error": 0.0246}, {"epoch": 37, "train_loss": 0.071689769980032, "grad_norm": 0.0834503248333931, "test_error": 0.0241}, {"epoch": 38, "train_loss": 0.0715282758733568, "grad_norm": 0.047441478818655014, "test_error": 0.0231}, {"epoch": 39, "train_loss": 0.07106049227169327, "grad_norm": 0.06068878620862961, "test_error": 0.0246}, {"epoch": 40, "train_loss": 0.07072826274849164, "grad_norm": 0.0557989776134491, "test_error": 0.0235}, {"epoch": 41, "train_loss": 0.07045538176233337, "grad_norm": 0.10423657298088074, "test_error": 0.0253}, {"epoch": 42, "train_loss": 0.07014807324699358, "grad_norm": 0.10033226013183594, "test_error": 0.0243}, {"epoch": 43, "train_loss": 0.06978253373247571, "grad_norm": 0.11820767819881439, "test_error": 0.0241}, {"epoch": 44, "train_loss": 0.06965465074612681, "grad_norm": 0.08603250235319138, "test_error": 0.0234}, {"epoch": 45, "train_loss": 0.06938094191086323, "grad_norm": 0.08069668710231781, "test_error": 0.0242}, {"epoch": 46, "train_loss": 0.06905997463079014, "grad_norm": 0.0913536325097084, "test_error": 0.0242}, {"epoch": 47, "train_loss": 0.06888834645670916, "grad_norm": 0.0751417949795723, "test_error": 0.0236}, {"epoch": 48, "train_loss": 0.06879645868033792, "grad_norm": 0.05916876718401909, "test_error": 0.0239}, {"epoch": 49, "train_loss": 0.06842996952024986, "grad_norm": 0.10405326634645462, "test_error": 0.0237}, {"epoch": 50, "train_loss": 0.06852733997360337, "grad_norm": 0.06253443658351898, "test_error": 0.0235}, {"epoch": 51, "train_loss": 0.0681936835355203, "grad_norm": 0.07570545375347137, "test_error": 0.0243}, {"epoch": 52, "train_loss": 0.06804130271500132, "grad_norm": 0.06822097301483154, "test_error": 0.0231}, {"epoch": 53, "train_loss": 0.06790415706378795, "grad_norm": 0.060161489993333817, "test_error": 0.0241}, {"epoch": 54, "train_loss": 0.06785693886076721, "grad_norm": 0.06539669632911682, "test_error": 0.0238}, {"epoch": 55, "train_loss": 0.0675279864515954, "grad_norm": 0.0483301505446434, "test_error": 0.0242}, {"epoch": 56, "train_loss": 0.06734587799829508, "grad_norm": 0.05570351332426071, "test_error": 0.0232}, {"epoch": 57, "train_loss": 0.06732893279010507, "grad_norm": 0.06862617284059525, "test_error": 0.0231}, {"epoch": 58, "train_loss": 0.06713499516900628, "grad_norm": 0.0655350312590599, "test_error": 0.0239}, {"epoch": 59, "train_loss": 0.06690158699747796, "grad_norm": 0.07632620632648468, "test_error": 0.0229}, {"epoch": 60, "train_loss": 0.06699986440343006, "grad_norm": 0.05702352151274681, "test_error": 0.0231}, {"epoch": 61, "train_loss": 0.06685404780103514, "grad_norm": 0.07746880501508713, "test_error": 0.0222}, {"epoch": 62, "train_loss": 0.06663157033567162, "grad_norm": 0.0748235285282135, "test_error": 0.0225}, {"epoch": 63, "train_loss": 0.0665943188003148, "grad_norm": 0.04585668444633484, "test_error": 0.0228}, {"epoch": 64, "train_loss": 0.06641644167253981, "grad_norm": 0.05424457788467407, "test_error": 0.0232}, {"epoch": 65, "train_loss": 0.0663824480867479, "grad_norm": 0.09005927294492722, "test_error": 0.0235}, {"epoch": 66, "train_loss": 0.0662928554917841, "grad_norm": 0.05682774633169174, "test_error": 0.0223}, {"epoch": 67, "train_loss": 0.06612089400365949, "grad_norm": 0.08348820358514786, "test_error": 0.0223}, {"epoch": 68, "train_loss": 0.0660001863814347, "grad_norm": 0.0565018504858017, "test_error": 0.0231}, {"epoch": 69, "train_loss": 0.06599735802656505, "grad_norm": 0.04260840639472008, "test_error": 0.023}, {"epoch": 70, "train_loss": 0.06582682153570932, "grad_norm": 0.10229572653770447, "test_error": 0.0229}, {"epoch": 71, "train_loss": 0.06596361343651855, "grad_norm": 0.03836400434374809, "test_error": 0.0224}, {"epoch": 72, "train_loss": 0.06581116365975079, "grad_norm": 0.04747166112065315, "test_error": 0.0221}, {"epoch": 73, "train_loss": 0.06560141745037011, "grad_norm": 0.10594626516103745, "test_error": 0.0236}, {"epoch": 74, "train_loss": 0.06561731660919032, "grad_norm": 0.03715172037482262, "test_error": 0.0226}, {"epoch": 75, "train_loss": 0.06558529717721588, "grad_norm": 0.04414495453238487, "test_error": 0.0223}, {"epoch": 76, "train_loss": 0.06544218861030338, "grad_norm": 0.04637860134243965, "test_error": 0.0227}, {"epoch": 77, "train_loss": 0.06515977535963369, "grad_norm": 0.06896820664405823, "test_error": 0.0228}, {"epoch": 78, "train_loss": 0.06523772067180834, "grad_norm": 0.04467910900712013, "test_error": 0.0221}, {"epoch": 79, "train_loss": 0.06505434320531397, "grad_norm": 0.0632530152797699, "test_error": 0.0224}, {"epoch": 80, "train_loss": 0.06497095646028174, "grad_norm": 0.061099689453840256, "test_error": 0.0227}, {"epoch": 81, "train_loss": 0.06508393521480806, "grad_norm": 0.09090151637792587, "test_error": 0.0236}, {"epoch": 82, "train_loss": 0.06493120965287866, "grad_norm": 0.07578864693641663, "test_error": 0.023}, {"epoch": 83, "train_loss": 0.06482912392237146, "grad_norm": 0.06493426114320755, "test_error": 0.0229}, {"epoch": 84, "train_loss": 0.06454432893435781, "grad_norm": 0.08152566850185394, "test_error": 0.0232}, {"epoch": 85, "train_loss": 0.06473569713761874, "grad_norm": 0.1089305728673935, "test_error": 0.0235}, {"epoch": 86, "train_loss": 0.06480674195557368, "grad_norm": 0.049019549041986465, "test_error": 0.023}, {"epoch": 87, "train_loss": 0.06456298588301676, "grad_norm": 0.09838654845952988, "test_error": 0.0237}, {"epoch": 88, "train_loss": 0.06453004959279982, "grad_norm": 0.09834189713001251, "test_error": 0.0231}, {"epoch": 89, "train_loss": 0.06455390671823019, "grad_norm": 0.07016795128583908, "test_error": 0.0224}, {"epoch": 90, "train_loss": 0.06430551616775726, "grad_norm": 0.05154410004615784, "test_error": 0.0225}, {"epoch": 91, "train_loss": 0.06449885053625136, "grad_norm": 0.028815509751439095, "test_error": 0.0223}, {"epoch": 92, "train_loss": 0.064200420991537, "grad_norm": 0.06049208343029022, "test_error": 0.0227}, {"epoch": 93, "train_loss": 0.06424561249746087, "grad_norm": 0.05431743711233139, "test_error": 0.0232}, {"epoch": 94, "train_loss": 0.0644945729050863, "grad_norm": 0.05859553441405296, "test_error": 0.0213}, {"epoch": 95, "train_loss": 0.06423329550140382, "grad_norm": 0.06383644044399261, "test_error": 0.0226}, {"epoch": 96, "train_loss": 0.06422975825691052, "grad_norm": 0.05279494822025299, "test_error": 0.0214}, {"epoch": 97, "train_loss": 0.06400681860659582, "grad_norm": 0.05543074011802673, "test_error": 0.0226}, {"epoch": 98, "train_loss": 0.06402633943170076, "grad_norm": 0.0603051595389843, "test_error": 0.0217}, {"epoch": 99, "train_loss": 0.0639832923580349, "grad_norm": 0.06183600053191185, "test_error": 0.022}, {"epoch": 100, "train_loss": 0.06414899422820114, "grad_norm": 0.06692598015069962, "test_error": 0.0225}, {"epoch": 101, "train_loss": 0.06405123552870161, "grad_norm": 0.06037783995270729, "test_error": 0.0218}, {"epoch": 102, "train_loss": 0.06386202661551457, "grad_norm": 0.05120266601443291, "test_error": 0.023}, {"epoch": 103, "train_loss": 0.06379713946433427, "grad_norm": 0.043161727488040924, "test_error": 0.0222}, {"epoch": 104, "train_loss": 0.06390341839320414, "grad_norm": 0.08746881037950516, "test_error": 0.0228}, {"epoch": 105, "train_loss": 0.06359469598564707, "grad_norm": 0.051363296806812286, "test_error": 0.0231}, {"epoch": 106, "train_loss": 0.06371789087155291, "grad_norm": 0.08376125991344452, "test_error": 0.0216}, {"epoch": 107, "train_loss": 0.06374741260092318, "grad_norm": 0.06590581685304642, "test_error": 0.0225}, {"epoch": 108, "train_loss": 0.06371422563163408, "grad_norm": 0.09135600179433823, "test_error": 0.0221}, {"epoch": 109, "train_loss": 0.06354245230164574, "grad_norm": 0.05818039923906326, "test_error": 0.0222}, {"epoch": 110, "train_loss": 0.0634758034159313, "grad_norm": 0.08241289854049683, "test_error": 0.0228}, {"epoch": 111, "train_loss": 0.06357348141390443, "grad_norm": 0.043493252247571945, "test_error": 0.0215}, {"epoch": 112, "train_loss": 0.06342277306962447, "grad_norm": 0.04583561047911644, "test_error": 0.0218}, {"epoch": 113, "train_loss": 0.06355067735169238, "grad_norm": 0.055114056915044785, "test_error": 0.0224}, {"epoch": 114, "train_loss": 0.0634044882255257, "grad_norm": 0.06874386966228485, "test_error": 0.0225}, {"epoch": 115, "train_loss": 0.06341386680103217, "grad_norm": 0.055087823420763016, "test_error": 0.0211}, {"epoch": 116, "train_loss": 0.0633614268777504, "grad_norm": 0.07358691841363907, "test_error": 0.0217}, {"epoch": 117, "train_loss": 0.06330425528372871, "grad_norm": 0.05087269842624664, "test_error": 0.0219}, {"epoch": 118, "train_loss": 0.06327547441141602, "grad_norm": 0.05586325004696846, "test_error": 0.0228}, {"epoch": 119, "train_loss": 0.06325103036516036, "grad_norm": 0.06685768812894821, "test_error": 0.0225}, {"epoch": 120, "train_loss": 0.06302547703675615, "grad_norm": 0.050110768526792526, "test_error": 0.022}, {"epoch": 121, "train_loss": 0.06312596252434499, "grad_norm": 0.07279623299837112, "test_error": 0.0217}, {"epoch": 122, "train_loss": 0.06305502876391013, "grad_norm": 0.08278345316648483, "test_error": 0.0227}, {"epoch": 123, "train_loss": 0.06317275529114219, "grad_norm": 0.09715823084115982, "test_error": 0.0224}, {"epoch": 124, "train_loss": 0.06317944579885806, "grad_norm": 0.03596021607518196, "test_error": 0.0223}, {"epoch": 125, "train_loss": 0.06293413790346433, "grad_norm": 0.06652960181236267, "test_error": 0.0222}, {"epoch": 126, "train_loss": 0.06306213614179675, "grad_norm": 0.06102653220295906, "test_error": 0.021}, {"epoch": 127, "train_loss": 0.06310996071378273, "grad_norm": 0.0465439148247242, "test_error": 0.0221}, {"epoch": 128, "train_loss": 0.06291906549127695, "grad_norm": 0.05085382238030434, "test_error": 0.0217}, {"epoch": 129, "train_loss": 0.06297607051886735, "grad_norm": 0.06632494926452637, "test_error": 0.0232}, {"epoch": 130, "train_loss": 0.06279536374316862, "grad_norm": 0.048018619418144226, "test_error": 0.0219}, {"epoch": 131, "train_loss": 0.06280612839519745, "grad_norm": 0.06372296810150146, "test_error": 0.0218}, {"epoch": 132, "train_loss": 0.06286790297580107, "grad_norm": 0.07231859862804413, "test_error": 0.022}, {"epoch": 133, "train_loss": 0.06284726362805426, "grad_norm": 0.0920274630188942, "test_error": 0.0218}, {"epoch": 134, "train_loss": 0.06285339627546879, "grad_norm": 0.06653982400894165, "test_error": 0.0227}, {"epoch": 135, "train_loss": 0.06284651426551864, "grad_norm": 0.05192999914288521, "test_error": 0.0221}, {"epoch": 136, "train_loss": 0.062471039164559136, "grad_norm": 0.05891447886824608, "test_error": 0.0213}, {"epoch": 137, "train_loss": 0.06248330806141409, "grad_norm": 0.05595708638429642, "test_error": 0.0212}, {"epoch": 138, "train_loss": 0.06249796193517977, "grad_norm": 0.09775833040475845, "test_error": 0.023}, {"epoch": 139, "train_loss": 0.06267766923160525, "grad_norm": 0.07204775512218475, "test_error": 0.0217}, {"epoch": 140, "train_loss": 0.06244040016197444, "grad_norm": 0.06343518942594528, "test_error": 0.0218}, {"epoch": 141, "train_loss": 0.06252950450723681, "grad_norm": 0.04539704695343971, "test_error": 0.0216}, {"epoch": 142, "train_loss": 0.062463824338755025, "grad_norm": 0.06010490283370018, "test_error": 0.0214}, {"epoch": 143, "train_loss": 0.06248950460771448, "grad_norm": 0.0849403664469719, "test_error": 0.0233}, {"epoch": 144, "train_loss": 0.06253348673792788, "grad_norm": 0.06892611086368561, "test_error": 0.0217}, {"epoch": 145, "train_loss": 0.06264044776104856, "grad_norm": 0.087700255215168, "test_error": 0.0218}, {"epoch": 146, "train_loss": 0.062338182780949866, "grad_norm": 0.08992042392492294, "test_error": 0.0224}, {"epoch": 147, "train_loss": 0.06261390012747142, "grad_norm": 0.08025378733873367, "test_error": 0.0215}, {"epoch": 148, "train_loss": 0.06245456159070212, "grad_norm": 0.06962981075048447, "test_error": 0.0216}, {"epoch": 149, "train_loss": 0.06223188538509809, "grad_norm": 0.08134619891643524, "test_error": 0.0222}, {"epoch": 150, "train_loss": 0.06235968283288336, "grad_norm": 0.03926052898168564, "test_error": 0.0218}, {"epoch": 151, "train_loss": 0.062420417608547725, "grad_norm": 0.0524754524230957, "test_error": 0.0224}, {"epoch": 152, "train_loss": 0.06228520441282308, "grad_norm": 0.05693027749657631, "test_error": 0.0216}, {"epoch": 153, "train_loss": 0.06230380752083147, "grad_norm": 0.04051314666867256, "test_error": 0.0221}, {"epoch": 154, "train_loss": 0.06212145149725257, "grad_norm": 0.06973688304424286, "test_error": 0.0217}, {"epoch": 155, "train_loss": 0.0624694877389896, "grad_norm": 0.05406724661588669, "test_error": 0.0224}, {"epoch": 156, "train_loss": 0.062331227118246416, "grad_norm": 0.05505373328924179, "test_error": 0.0221}, {"epoch": 157, "train_loss": 0.06218694544264387, "grad_norm": 0.07368095964193344, "test_error": 0.0222}, {"epoch": 158, "train_loss": 0.06201947409457838, "grad_norm": 0.049622543156147, "test_error": 0.0225}, {"epoch": 159, "train_loss": 0.06216947527208443, "grad_norm": 0.08029181510210037, "test_error": 0.0225}, {"epoch": 160, "train_loss": 0.06220515021720591, "grad_norm": 0.06324853003025055, "test_error": 0.021}, {"epoch": 161, "train_loss": 0.062140688283989824, "grad_norm": 0.041208069771528244, "test_error": 0.021}, {"epoch": 162, "train_loss": 0.06222626789410909, "grad_norm": 0.05776591598987579, "test_error": 0.0215}, {"epoch": 163, "train_loss": 0.06195174965700911, "grad_norm": 0.07414156198501587, "test_error": 0.0223}, {"epoch": 164, "train_loss": 0.06201131700629291, "grad_norm": 0.044456955045461655, "test_error": 0.0212}, {"epoch": 165, "train_loss": 0.06213681384783316, "grad_norm": 0.059755489230155945, "test_error": 0.0216}, {"epoch": 166, "train_loss": 0.062026464743966545, "grad_norm": 0.06046354025602341, "test_error": 0.0218}, {"epoch": 167, "train_loss": 0.061899904647977864, "grad_norm": 0.061427053064107895, "test_error": 0.0218}, {"epoch": 168, "train_loss": 0.062002197590404345, "grad_norm": 0.057380471378564835, "test_error": 0.0218}, {"epoch": 169, "train_loss": 0.06197722329884224, "grad_norm": 0.09865262359380722, "test_error": 0.0219}, {"epoch": 170, "train_loss": 0.06191802083219712, "grad_norm": 0.06957150995731354, "test_error": 0.0219}, {"epoch": 171, "train_loss": 0.06201492846797919, "grad_norm": 0.07001352310180664, "test_error": 0.0209}, {"epoch": 172, "train_loss": 0.06195225357784269, "grad_norm": 0.050284504890441895, "test_error": 0.0224}, {"epoch": 173, "train_loss": 0.061865253036861155, "grad_norm": 0.08692685514688492, "test_error": 0.022}, {"epoch": 174, "train_loss": 0.06180876693026706, "grad_norm": 0.04961637407541275, "test_error": 0.021}, {"epoch": 175, "train_loss": 0.06171005561414252, "grad_norm": 0.050012532621622086, "test_error": 0.0219}, {"epoch": 176, "train_loss": 0.06173639640188776, "grad_norm": 0.06724914908409119, "test_error": 0.0206}, {"epoch": 177, "train_loss": 0.06185256615001708, "grad_norm": 0.054338328540325165, "test_error": 0.0215}, {"epoch": 178, "train_loss": 0.06169358672273423, "grad_norm": 0.06688014417886734, "test_error": 0.0215}, {"epoch": 179, "train_loss": 0.061792847214111435, "grad_norm": 0.05219325050711632, "test_error": 0.0213}, {"epoch": 180, "train_loss": 0.06161086532599681, "grad_norm": 0.04969624802470207, "test_error": 0.0211}, {"epoch": 181, "train_loss": 0.06176462062066033, "grad_norm": 0.060500722378492355, "test_error": 0.0213}, {"epoch": 182, "train_loss": 0.06159765543158088, "grad_norm": 0.05896919220685959, "test_error": 0.0225}, {"epoch": 183, "train_loss": 0.061643615355695756, "grad_norm": 0.07183737307786942, "test_error": 0.0212}, {"epoch": 184, "train_loss": 0.06172957110934658, "grad_norm": 0.0613592229783535, "test_error": 0.0222}, {"epoch": 185, "train_loss": 0.06161606930330163, "grad_norm": 0.0803927406668663, "test_error": 0.0221}, {"epoch": 186, "train_loss": 0.06184003033079595, "grad_norm": 0.09830828756093979, "test_error": 0.021}, {"epoch": 187, "train_loss": 0.06180703280708015, "grad_norm": 0.0593671016395092, "test_error": 0.0209}, {"epoch": 188, "train_loss": 0.06178108996609808, "grad_norm": 0.06252734363079071, "test_error": 0.021}, {"epoch": 189, "train_loss": 0.061556034873782965, "grad_norm": 0.08846142143011093, "test_error": 0.0212}, {"epoch": 190, "train_loss": 0.06172047380348279, "grad_norm": 0.044803086668252945, "test_error": 0.0206}, {"epoch": 191, "train_loss": 0.061637278827198314, "grad_norm": 0.057687465101480484, "test_error": 0.0217}, {"epoch": 192, "train_loss": 0.061632107210345566, "grad_norm": 0.06513065844774246, "test_error": 0.0213}, {"epoch": 193, "train_loss": 0.06153235318529187, "grad_norm": 0.05293254181742668, "test_error": 0.0219}, {"epoch": 194, "train_loss": 0.06143236857136556, "grad_norm": 0.08108063042163849, "test_error": 0.0217}, {"epoch": 195, "train_loss": 0.061543383960534506, "grad_norm": 0.04427848756313324, "test_error": 0.0217}, {"epoch": 196, "train_loss": 0.061643749965510024, "grad_norm": 0.049905214458703995, "test_error": 0.0215}, {"epoch": 197, "train_loss": 0.06154535163527665, "grad_norm": 0.04913521558046341, "test_error": 0.021}, {"epoch": 198, "train_loss": 0.061325992484790426, "grad_norm": 0.09639338403940201, "test_error": 0.022}, {"epoch": 199, "train_loss": 0.061402165608888025, "grad_norm": 0.03738386556506157, "test_error": 0.0218}, {"epoch": 200, "train_loss": 0.06137945329964471, "grad_norm": 0.06497116386890411, "test_error": 0.0205}, {"epoch": 201, "train_loss": 0.06148744089055496, "grad_norm": 0.11198064684867859, "test_error": 0.0222}, {"epoch": 202, "train_loss": 0.06131855643065258, "grad_norm": 0.09054096788167953, "test_error": 0.021}, {"epoch": 203, "train_loss": 0.06142379027304317, "grad_norm": 0.08461187779903412, "test_error": 0.0222}, {"epoch": 204, "train_loss": 0.061310689206894795, "grad_norm": 0.06696388125419617, "test_error": 0.0221}, {"epoch": 205, "train_loss": 0.06134516205599842, "grad_norm": 0.10153501480817795, "test_error": 0.0215}, {"epoch": 206, "train_loss": 0.06134841348038753, "grad_norm": 0.04261744022369385, "test_error": 0.021}, {"epoch": 207, "train_loss": 0.06125937485442652, "grad_norm": 0.0927707701921463, "test_error": 0.0226}, {"epoch": 208, "train_loss": 0.06144870556530077, "grad_norm": 0.03619479760527611, "test_error": 0.0207}, {"epoch": 209, "train_loss": 0.06142195452121087, "grad_norm": 0.047611698508262634, "test_error": 0.0204}, {"epoch": 210, "train_loss": 0.06124210491301104, "grad_norm": 0.07420157641172409, "test_error": 0.0225}, {"epoch": 211, "train_loss": 0.06124030705407495, "grad_norm": 0.047026269137859344, "test_error": 0.021}, {"epoch": 212, "train_loss": 0.06107549496423841, "grad_norm": 0.05780145898461342, "test_error": 0.0224}, {"epoch": 213, "train_loss": 0.06125837236200459, "grad_norm": 0.05259610339999199, "test_error": 0.0214}, {"epoch": 214, "train_loss": 0.06116574714051482, "grad_norm": 0.048948027193546295, "test_error": 0.021}, {"epoch": 215, "train_loss": 0.06146852944119988, "grad_norm": 0.03896145895123482, "test_error": 0.0213}, {"epoch": 216, "train_loss": 0.06102072324308877, "grad_norm": 0.05723724141716957, "test_error": 0.0215}, {"epoch": 217, "train_loss": 0.06142770200568096, "grad_norm": 0.0498952679336071, "test_error": 0.0212}, {"epoch": 218, "train_loss": 0.06119103991319814, "grad_norm": 0.06831557303667068, "test_error": 0.0206}, {"epoch": 219, "train_loss": 0.06128583144169534, "grad_norm": 0.052760034799575806, "test_error": 0.0217}, {"epoch": 220, "train_loss": 0.06126598433343073, "grad_norm": 0.061309363692998886, "test_error": 0.0214}, {"epoch": 221, "train_loss": 0.06112574610259617, "grad_norm": 0.052411291748285294, "test_error": 0.0209}, {"epoch": 222, "train_loss": 0.0610897451970571, "grad_norm": 0.05629326030611992, "test_error": 0.0216}, {"epoch": 223, "train_loss": 0.061052286230959, "grad_norm": 0.06650315970182419, "test_error": 0.0216}, {"epoch": 224, "train_loss": 0.061205126007281556, "grad_norm": 0.036982160061597824, "test_error": 0.021}, {"epoch": 225, "train_loss": 0.061125743931198184, "grad_norm": 0.06559879332780838, "test_error": 0.022}, {"epoch": 226, "train_loss": 0.061118648495040055, "grad_norm": 0.06462262570858002, "test_error": 0.0208}, {"epoch": 227, "train_loss": 0.06084205452383806, "grad_norm": 0.0662437230348587, "test_error": 0.0216}, {"epoch": 228, "train_loss": 0.060981419451360125, "grad_norm": 0.04397139325737953, "test_error": 0.0218}, {"epoch": 229, "train_loss": 0.06102613745583221, "grad_norm": 0.032536569982767105, "test_error": 0.0215}, {"epoch": 230, "train_loss": 0.060962877473667805, "grad_norm": 0.06811290979385376, "test_error": 0.0213}, {"epoch": 231, "train_loss": 0.06111626029555919, "grad_norm": 0.06277960538864136, "test_error": 0.0208}, {"epoch": 232, "train_loss": 0.060966630108712706, "grad_norm": 0.0716462954878807, "test_error": 0.0211}, {"epoch": 233, "train_loss": 0.060966008660635757, "grad_norm": 0.10118603706359863, "test_error": 0.0221}, {"epoch": 234, "train_loss": 0.06103014276368776, "grad_norm": 0.04617665335536003, "test_error": 0.0209}, {"epoch": 235, "train_loss": 0.060765296553475005, "grad_norm": 0.052279047667980194, "test_error": 0.0222}, {"epoch": 236, "train_loss": 0.060890592178096996, "grad_norm": 0.07116977870464325, "test_error": 0.0223}, {"epoch": 237, "train_loss": 0.06086298491693257, "grad_norm": 0.0715177059173584, "test_error": 0.021}, {"epoch": 238, "train_loss": 0.060950170656937794, "grad_norm": 0.12717732787132263, "test_error": 0.0223}, {"epoch": 239, "train_loss": 0.060898156670640066, "grad_norm": 0.06935158371925354, "test_error": 0.0206}, {"epoch": 240, "train_loss": 0.060840441301853086, "grad_norm": 0.07309781014919281, "test_error": 0.0209}, {"epoch": 241, "train_loss": 0.0608243009079985, "grad_norm": 0.08128344267606735, "test_error": 0.0221}, {"epoch": 242, "train_loss": 0.060791588669924145, "grad_norm": 0.06947117298841476, "test_error": 0.022}, {"epoch": 243, "train_loss": 0.060893396031790566, "grad_norm": 0.05456022545695305, "test_error": 0.0209}, {"epoch": 244, "train_loss": 0.06077712845936185, "grad_norm": 0.048590295016765594, "test_error": 0.0202}, {"epoch": 245, "train_loss": 0.06073196888305635, "grad_norm": 0.06795060634613037, "test_error": 0.0212}, {"epoch": 246, "train_loss": 0.06090397655174214, "grad_norm": 0.03682897984981537, "test_error": 0.0202}, {"epoch": 247, "train_loss": 0.06095115998191371, "grad_norm": 0.08108347654342651, "test_error": 0.0207}, {"epoch": 248, "train_loss": 0.06078445004775616, "grad_norm": 0.07959985733032227, "test_error": 0.0212}, {"epoch": 249, "train_loss": 0.06086630906640009, "grad_norm": 0.07094931602478027, "test_error": 0.0209}, {"epoch": 250, "train_loss": 0.060795822943211536, "grad_norm": 0.0652608796954155, "test_error": 0.0214}, {"epoch": 251, "train_loss": 0.060873542501891885, "grad_norm": 0.05649624392390251, "test_error": 0.0215}, {"epoch": 252, "train_loss": 0.06081796531666381, "grad_norm": 0.04306609183549881, "test_error": 0.0212}, {"epoch": 253, "train_loss": 0.06080819677084219, "grad_norm": 0.07722067087888718, "test_error": 0.0207}, {"epoch": 254, "train_loss": 0.06074859735418189, "grad_norm": 0.05634832754731178, "test_error": 0.0214}, {"epoch": 255, "train_loss": 0.06080923575772128, "grad_norm": 0.04742525517940521, "test_error": 0.0213}, {"epoch": 256, "train_loss": 0.06061005406644351, "grad_norm": 0.06618692725896835, "test_error": 0.0218}, {"epoch": 257, "train_loss": 0.06069454935930359, "grad_norm": 0.04275094345211983, "test_error": 0.0209}, {"epoch": 258, "train_loss": 0.060604319523981154, "grad_norm": 0.05449860915541649, "test_error": 0.0216}, {"epoch": 259, "train_loss": 0.06075399311833705, "grad_norm": 0.04815163090825081, "test_error": 0.021}, {"epoch": 260, "train_loss": 0.06070011585366834, "grad_norm": 0.06732528656721115, "test_error": 0.0215}, {"epoch": 261, "train_loss": 0.060683224952973736, "grad_norm": 0.04815017059445381, "test_error": 0.0213}, {"epoch": 262, "train_loss": 0.06065945353580173, "grad_norm": 0.07055658102035522, "test_error": 0.0203}, {"epoch": 263, "train_loss": 0.06074205590534257, "grad_norm": 0.07079143077135086, "test_error": 0.0212}, {"epoch": 264, "train_loss": 0.06062238124445624, "grad_norm": 0.0698799416422844, "test_error": 0.0209}, {"epoch": 265, "train_loss": 0.06073009890715669, "grad_norm": 0.08288029581308365, "test_error": 0.0208}, {"epoch": 266, "train_loss": 0.06069852741479796, "grad_norm": 0.06957022100687027, "test_error": 0.021}, {"epoch": 267, "train_loss": 0.06065305455698399, "grad_norm": 0.0653989315032959, "test_error": 0.0206}, {"epoch": 268, "train_loss": 0.06052194233739283, "grad_norm": 0.04712273180484772, "test_error": 0.0209}, {"epoch": 269, "train_loss": 0.0604664348437606, "grad_norm": 0.06365838646888733, "test_error": 0.0206}, {"epoch": 270, "train_loss": 0.06051166198546222, "grad_norm": 0.043501920998096466, "test_error": 0.0201}, {"epoch": 271, "train_loss": 0.060651480724685826, "grad_norm": 0.05811607092618942, "test_error": 0.0208}, {"epoch": 272, "train_loss": 0.06054617691457194, "grad_norm": 0.07497447729110718, "test_error": 0.0209}, {"epoch": 273, "train_loss": 0.06046390123781748, "grad_norm": 0.07475458830595016, "test_error": 0.0209}, {"epoch": 274, "train_loss": 0.060465961781543835, "grad_norm": 0.11315646767616272, "test_error": 0.0212}, {"epoch": 275, "train_loss": 0.06043505505875995, "grad_norm": 0.05442171171307564, "test_error": 0.0208}, {"epoch": 276, "train_loss": 0.06045557651410733, "grad_norm": 0.04882226139307022, "test_error": 0.0213}, {"epoch": 277, "train_loss": 0.06059240817724882, "grad_norm": 0.10500490665435791, "test_error": 0.0221}, {"epoch": 278, "train_loss": 0.06060704226970362, "grad_norm": 0.057145167142152786, "test_error": 0.0207}, {"epoch": 279, "train_loss": 0.060438573624065614, "grad_norm": 0.10232524573802948, "test_error": 0.0219}, {"epoch": 280, "train_loss": 0.06056008969280326, "grad_norm": 0.07846478372812271, "test_error": 0.0216}, {"epoch": 281, "train_loss": 0.06044508513864518, "grad_norm": 0.05707366392016411, "test_error": 0.0205}, {"epoch": 282, "train_loss": 0.060570173486640365, "grad_norm": 0.040779124945402145, "test_error": 0.0209}, {"epoch": 283, "train_loss": 0.06040245358301521, "grad_norm": 0.05782284587621689, "test_error": 0.0217}, {"epoch": 284, "train_loss": 0.060318061816991154, "grad_norm": 0.05833706632256508, "test_error": 0.0213}, {"epoch": 285, "train_loss": 0.06067489106518527, "grad_norm": 0.0698915496468544, "test_error": 0.0213}, {"epoch": 286, "train_loss": 0.06050585613085423, "grad_norm": 0.044890906661748886, "test_error": 0.0208}, {"epoch": 287, "train_loss": 0.06051052219882452, "grad_norm": 0.06899286806583405, "test_error": 0.0201}, {"epoch": 288, "train_loss": 0.06052493485540617, "grad_norm": 0.039646487683057785, "test_error": 0.0209}, {"epoch": 289, "train_loss": 0.060438310200193274, "grad_norm": 0.05164088308811188, "test_error": 0.021}, {"epoch": 290, "train_loss": 0.06043331663029191, "grad_norm": 0.06386566907167435, "test_error": 0.0207}, {"epoch": 291, "train_loss": 0.06014021222157559, "grad_norm": 0.0667969137430191, "test_error": 0.0207}, {"epoch": 292, "train_loss": 0.060308284293433344, "grad_norm": 0.06390482187271118, "test_error": 0.0213}, {"epoch": 293, "train_loss": 0.06043898077076301, "grad_norm": 0.05579188093543053, "test_error": 0.0201}, {"epoch": 294, "train_loss": 0.06061030892211905, "grad_norm": 0.09407270699739456, "test_error": 0.0211}, {"epoch": 295, "train_loss": 0.06048276612211097, "grad_norm": 0.06263279169797897, "test_error": 0.0204}, {"epoch": 296, "train_loss": 0.06061088263361793, "grad_norm": 0.03984326124191284, "test_error": 0.0209}, {"epoch": 297, "train_loss": 0.060290170517827694, "grad_norm": 0.07207699865102768, "test_error": 0.0207}, {"epoch": 298, "train_loss": 0.06043497402172458, "grad_norm": 0.05688125640153885, "test_error": 0.0217}, {"epoch": 299, "train_loss": 0.060313098576754175, "grad_norm": 0.052229173481464386, "test_error": 0.0205}, {"epoch": 300, "train_loss": 0.06032470747473417, "grad_norm": 0.03832799941301346, "test_error": 0.0199}]}